<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title></title>
    <link>http://localhost:4000</link>
    <description>
      Random walk through life
    </description>
    
        
            <item>
                <title>Hierarchical Models in Numpyro</title>
                <link>http://localhost:4000/2021/01/29/hierarchical-models/</link>
                <content:encoded>
                    <![CDATA[
                    <p>In this post, I explore 3 different formulations for modelling repeated Bernoulli / binary trial data: complete pooling where all items have the same chance of success, no pooling where each item has an independent chance of success and partial pooling where data across items are shared to estimate parameters. To demonstrate, I model the free throw percentage of NBA players using Numpyro. Another famous example is modelling baseball batting averages, but I like basketball a lot more than baseball!</p>

<p>All the code for this post is available <a href="https://www.kaggle.com/jramkiss/pooling-in-hierarchical-models-with-numpyro">here</a>.</p>

<p>In a repeated Bernoulli / binary trial, our data consists of $n$ units where each unit, $i$, records $y_i$ successes in $K_i$ trials / attempts. Two simple examples are in baseball and basketball, but they get a lot more interesting than this.</p>

<ul>
  <li>Baseball batters: Every pitch faced is a trial and every hit is a success. Each batter is a unit.</li>
  <li>Basketball players taking free throws: Every free throw is a trial and every time they make it is a success. Each player is a unit</li>
</ul>

<h2 id="problem-and-data">Problem and Data</h2>

<p>I’ll use <a href="https://www.kaggle.com/sebastianmantey/nba-free-throws">NBA free throw data</a> to model the free throw percentage of top players in the 2015-2016 season. To have a sort of train/test split, only the first quarter of the season will be used to fit the models and the other $\frac{3}{4}$ will be for testing / other stuff. Here’s what the data looks like after some manipulation:</p>

<p align="center">
  <img src="/assets/NBA-free-throw-data.png" width="60%" height="60%" />
</p>

<p> </p>

<h2 id="overall-model">Overall Model</h2>

<p>The three formulations in this post branch out from the same canonical model. We have 16 players, $i = 1…16$, and our goal is to estimate the free throw percentage (chance of success) for each one, $\theta_i$. Our data consists of the number of shots made for player, $y_i$, and the number of attempts for each player, $K_i$. Using this, the number of free throws made, $y_i$, follows a Binomial distribution conditional on the number of attempts and probability of success:</p>

\[p(y_i \mid \theta_i, K_i) = \text{Binomial}(\theta_i, K_i)\]

<p>To help with inference, we transform $\theta$ to a log-odds parameter, $\alpha$. Using $\alpha$ will change the distribution of $y_i$ from a Binomial distribution to a BinomialLogit, but the intuition is the same.</p>

\[\alpha = \text{logit}(\theta) = \text{log}\frac{\theta}{1 - \theta}\]

\[\theta = \text{InverseLogit}(\alpha) = \text{sigmoid}(\alpha)\]

\[p(y_i \mid K_i, \alpha_i) = \text{BinomialLogit}(K_i, \alpha)\]

<p>We are interested in estimating $\theta_i = \text{sigmoid}(\alpha_i)$, and our 3 formulations make different assumptions to do this.</p>

<p> </p>

<h3 id="complete-pooling---same-theta-for-every-player">Complete Pooling - Same $\theta$ for every player</h3>

<p>In the complete pooling formulation, each player has the same chance of success parameter. This translates to each player having the same chance of making a free throw. The advantage of this is that we can aggregate all attempts and all successes for the players to “get” more data. However, this is a terrible assumption because we know some players are better at making free throws than others.</p>

<p>For this model, the likelihood and prior are below, notice that $\theta$ (and by extension, $\alpha$) is not indexed because there is only 1.</p>

\[p(y_i \mid K_i, \theta) = \text{Binomial}(K_i. \theta)\]

\[p(y_i \mid K_i, \alpha) = \text{BinomialLogit}(K_i, \alpha)\]

\[p(\alpha) = N(1, 1)\]

<p>The prior on $\alpha$ can be interpreted as $95\%$ of values falling between a $0.26$ and $0.95$ chance of success.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fully_pooled</span><span class="p">(</span><span class="n">ft_attempts</span><span class="p">,</span> <span class="n">ft_makes</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
    <span class="n">num_players</span> <span class="o">=</span> <span class="n">ft_attempts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">alpha</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"alpha"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># prior on \alpha
</span>    <span class="n">theta</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">deterministic</span><span class="p">(</span><span class="s">"theta"</span><span class="p">,</span> <span class="n">jax</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span> <span class="c1"># need to use arviz
</span>    <span class="k">with</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">plate</span><span class="p">(</span><span class="s">"num_players"</span><span class="p">,</span> <span class="n">num_players</span><span class="p">):</span>
        <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"obs"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">BinomialLogits</span><span class="p">(</span><span class="n">total_count</span> <span class="o">=</span> <span class="n">ft_attempts</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">alpha</span><span class="p">),</span> 
                       <span class="n">obs</span><span class="o">=</span><span class="n">ft_makes</span><span class="p">)</span>
</code></pre></div></div>

<p>The posterior distribution for $\theta$ is below. Judging from the interval, we would be hard-pressed to find a player with a free throw percentage over $83.5\%$, however, $9$ out of the $16$ players analyzed have a free throw percentage higher than $83.5\%$. Aside from the assumptions of this model being completely wrong, it seems like the bi-product is a gross underestimation of players’ abilities. I guess this is expected since there will also be some overestimation for lower-ability players.</p>

<p align="center">
  <img src="/assets/NBA-free-throw-fully-pooled-theta.png" width="75%" height="75%" />
</p>

<p> </p>

<h3 id="no-pooling---independent-theta_i-for-each-player">No Pooling - Independent $\theta_i$ for each player</h3>

<p>The no pooling model is the exact opposite of the complete pooling model, where each player has a separate and independent chance of success. The formulation looks similar with a subtle difference, $\theta$ now becomes $\theta_i$ because there is a separate one for each player. Practically, this is exactly what we want as we know that each player has different free-throw abilities. However, we run into problems when we take into consideration the size of our dataset. We only have around 150 attempts for each player and have to use this to come up with a reliable estimate of ability. We’ll see the impact of this soon.</p>

\[p(y_i \mid \theta_i, K_i) = \text{Binomial}(\theta_i, K_i)\]

\[p(y_i \mid K_i, \alpha_i) = \text{BinomialLogit}(K_i, \alpha_i)\]

\[p(\alpha_i) = N(1, 1)\]

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">no_pooling</span> <span class="p">(</span><span class="n">ft_attempts</span><span class="p">,</span> <span class="n">ft_makes</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">num_players</span> <span class="o">=</span> <span class="n">ft_attempts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">plate</span><span class="p">(</span><span class="s">"players"</span><span class="p">,</span> <span class="n">num_players</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"alpha"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span> <span class="c1"># prior
</span>        <span class="k">assert</span> <span class="n">alpha</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_players</span><span class="p">,),</span> <span class="s">"alpha shape wrong"</span> <span class="c1"># one alpha for each player
</span>        <span class="n">theta</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">deterministic</span><span class="p">(</span><span class="s">"theta"</span><span class="p">,</span> <span class="n">jax</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"obs"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">BinomialLogits</span><span class="p">(</span><span class="n">total_count</span><span class="o">=</span><span class="n">ft_attempts</span><span class="p">,</span> <span class="n">logits</span><span class="o">=</span><span class="n">alpha</span><span class="p">),</span> 
                              <span class="n">obs</span> <span class="o">=</span> <span class="n">ft_makes</span><span class="p">)</span> <span class="c1"># likelihood
</span></code></pre></div></div>

<p>The posterior distributions for each $\theta$ are below:</p>

<p align="center">
  <img src="/assets/NBA-free-throw-no-pooling-theta(1).png" width="100%" height="100%" />
  <img src="/assets/NBA-free-throw-no-pooling-theta(2).png" width="100%" height="100%" />
</p>

<p> </p>

<p>It’s difficult to evaluate these estimates using only this graph, but one thing we can note is the size of the intervals. Many of them overlap significantly with a free throw percentage of $90\%$ and higher. This is an extremely high percentage, which is apparently close to getting you onto the top <a href="http://www.iweblists.com/sports/basketball/FreeThrowPercent_s.html">50 all-time list</a>. So it seems like the no-pooling formulation overestimates the player’s abilities.</p>

<p>Here is probably where I should note that I’m not particularly familiar with the difference between a good and great free throw percentage, but some Googling can go a long way.</p>

<p> </p>

<h3 id="partial-pooling---hierarchical-model">Partial Pooling - Hierarchical Model</h3>

<p>We ideally want a balance between the two extremes of no-pooling and complete-pooling, and this comes in the form of a partially pooled model. This model has a very subtle but important difference to the <code class="language-plaintext highlighter-rouge">no pooling</code> model which is in how we generate $\alpha_i$. Instead of sampling $\alpha_i$ directly from $N(1, 1)$, we estimate the mean, $\mu$, and standard deviation, $\sigma$, of $p(\alpha_i)$ using hyper-priors. Here, $\mu$ can be interpreted as the population chance of success. This difference may seem inconsequential but in small data settings, it makes the world of difference.</p>

\[p(y_i \mid K_i, \theta_i) = \text{Binomial}(K_i, \theta)\]

\[p(y_i \mid K_i, \alpha_i) = \text{BinomialLogit}(K_i, \alpha)\]

\[p(\alpha_i \mid \mu, \sigma) = \text{Normal}(\mu, \sigma)\]

\[p(\mu) = N(1, 1)\]

\[p(\sigma) = N(0, 1)\]

<p> </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">partial_pooling</span> <span class="p">(</span><span class="n">ft_attempts</span><span class="p">,</span> <span class="n">ft_makes</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
    <span class="n">num_players</span> <span class="o">=</span> <span class="n">ft_attempts</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">mu</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"mu"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">sigma</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"sigma"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="k">with</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">plate</span><span class="p">(</span><span class="s">"players"</span><span class="p">,</span> <span class="n">num_players</span><span class="p">):</span>
        <span class="n">alpha</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"alpha"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">))</span>
        <span class="n">theta</span> <span class="o">=</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">deterministic</span><span class="p">(</span><span class="s">"theta"</span><span class="p">,</span> <span class="n">jax</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">alpha</span><span class="p">))</span>
        <span class="k">assert</span> <span class="n">alpha</span><span class="p">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">num_players</span><span class="p">,</span> <span class="p">),</span> <span class="s">"alpha shape wrong"</span>
        <span class="k">return</span> <span class="n">numpyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"y"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">BinomialLogits</span><span class="p">(</span><span class="n">logits</span> <span class="o">=</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">total_count</span> <span class="o">=</span> <span class="n">ft_attempts</span><span class="p">),</span> 
                              <span class="n">obs</span> <span class="o">=</span> <span class="n">ft_makes</span><span class="p">)</span>
</code></pre></div></div>

<p> </p>

<p>The plots below compare the posterior densities for the partial pooled and no-pooled models. The intervals from the partial pooled are narrower and seem better calibrated to what we expect to see in real life. Only three intervals overlap with $90\%$, and based on the players they seem reasonable.</p>

<p>While running these experiments, there was a noticeable difference in the posterior intervals when the amount of data is reduced. As the size of data was reduced, the hierarchical model became much more reliable than the no-pooling model.</p>

<p align="center">
  <img src="/assets/NBA-free-throw-partial-pooling-theta(1).png" width="100%" height="100%" />
  <img src="/assets/NBA-free-throw-partial-pooling-theta(2).png" width="100%" height="100%" />
</p>

<p> </p>

<h3 id="where-does-the-difference-come-from">Where does the difference come from?</h3>

<p>The partially pooled and non-pooled models have very similar formulations but produce very different posterior distributions. The most obvious difference in the formulation the prior on $\alpha_i$. The partial pooling formulation has more flexibility here as both $\mu$ an $\sigma$ are estimated from the data. Below I compare $p(\alpha)$ for the partially pooled and non-pooled models and it seems like the partially pooled prior has more variance than the non-pooled model.</p>

<p>I was interested to see the impact of flatter priors on the model. However, after increasing the prior variance for the non-pooled model, interval estimates were too wide to be useful, this is because we have such small data on each player. On the other hand, the interval estimates produced by the hierarchical model were very similar to before, this is because the hyper-priors are estimated using population data, which we have more of because of pooling. It turns out that as we collect more and more data, the no-pooling and partially pooled formulations converge to the same solutions.</p>

<p align="center">
  <img src="/assets/NBA-free-throw-priors.png" width="100%" height="100%" />
</p>

<p> </p>

<h3 id="checking-model-interpretation">Checking Model Interpretation</h3>

<p>Above I mentioned that an interpretation of $\mu$ in the hierarchical model is the population chance of success. In our complete pooling formulation, $\theta$ is exactly the population chance of success. Here I compare the posterior distributions of these two parameters to see how similar they are. Before this is done, $\mu$ needs to be transformed from a log-odds parameter to a probability with $\text{sigmoid}(\mu)$.</p>

<p align="center">
  <img src="/assets/NBA-free-throw-mu-and-sigma.png" width="75%" height="75%" />
</p>

<p> </p>

<h2 id="conclusion">Conclusion</h2>

<p>There is a subtle but interesting difference between the no-pooling and partial pooling formulations that becomes more apparent as the data gets smaller. As we get more and more data, these two models converge to the same solutions.</p>

<p> </p>

<h2 id="resources">Resources</h2>

<ul>
  <li><a href="https://cran.r-project.org/web/packages/rstanarm/vignettes/pooling.html">Hierarchical Partial Pooling for Repeated Binary Trials</a></li>
  <li><a href="https://arviz-devs.github.io/arviz/getting_started/CreatingInferenceData.html#from-numpyro">Numpyro with Arviz</a></li>
  <li><a href="https://discovery.ucl.ac.uk/id/eprint/16040/1/16040.pdf">Bayesian hierarchical model for the prediction of football results</a></li>
</ul>

<!-- 
## Resources

- [Modeling Rates/Proportions using Beta Regression](https://cran.r-project.org/web/packages/rstanarm/vignettes/betareg.html)
- [Estimating Generalized Linear Models for Binary and Binomial Data](https://cran.r-project.org/web/packages/rstanarm/vignettes/binomial.html)
- [Estimating Generalized Linear Models for Continuous Data](https://cran.r-project.org/web/packages/rstanarm/vignettes/continuous.html)
- [Estimating Generalized Linear Models for Count Data](https://cran.r-project.org/web/packages/rstanarm/vignettes/count.html)
- [Estimating Generalized (Non-)Linear Models with Group-Specific Terms](https://cran.r-project.org/web/packages/rstanarm/vignettes/glmer.html)
- [Estimating Joint Models for Longitudinal and Time-to-Event Data](https://cran.r-project.org/web/packages/rstanarm/vignettes/jm.html)
- [Estimating Regularized Linear Models](https://cran.r-project.org/web/packages/rstanarm/vignettes/lm.html)
- [Estimating Ordinal Regression Models](https://cran.r-project.org/web/packages/rstanarm/vignettes/polr.html)
- [Estimating ANOVA Models](https://cran.r-project.org/web/packages/rstanarm/vignettes/aov.html) -->

<!-- 

# Outstanding Questions
- How do we actually share data in the hierarchical model? What happen if we dont have \alpha in this model?
- Are hierarchical model overparametrized?


## Key Questions

- What really makes multi-level / hierarchical modelling so much "better"? 
- How is a hierarchical model even better? Is it just the change in posterior? What happens if we use flatter priors?
- What happens to parameter variance when we have hierarchical priors?

### Reading Material

- Statistical Rethinking - Chapter 13
- [Multilevel modelling in PyStan](https://widdowquinn.github.io/Teaching-Stan-Hierarchical-Modelling/07-partial_pooling_intro.html): Jupyter notebook with PyStan example
- [Bayesian Hierarchical Modelling at Scale](https://florianwilhelm.info/2020/10/bayesian_hierarchical_modelling_at_scale/): Post comparing PyMC3 to Pyro and using Pyro for a task with lots of data.
- [Notes on Hierarchical Models](https://vioshyvo.github.io/Bayesian_inference/hierarchical-models.html)
- [CMU Hierarchical Models Intro](http://www.stat.cmu.edu/~brian/463-663/week10/Chapter%2009.pdf)
- [Best of both worlds: Hierarchical models](https://twiecki.io/blog/2014/03/17/bayesian-glms-3/)
- [Radon data analysis](https://github.com/fonnesbeck/multilevel_modeling/blob/master/multilevel_modeling.ipynb)
- [Shrinkage in hierarchical models](http://doingbayesiandataanalysis.blogspot.com/2012/11/shrinkage-in-multi-level-hierarchical.html)
- [Imperial slide deck on Bayesian hierarchical modeling](https://www.imperial.ac.uk/media/imperial-college/research-centres-and-groups/astrophysics/public/icic/data-analysis-workshop/2018/BHMs.pdf)
- [CMU Hierarchical Models](http://www.stat.cmu.edu/~brian/463-663/week11/Chapter%2009.pdf)
- [Gelman post on BHM](https://statmodeling.stat.columbia.edu/2018/03/24/economist-wrote-asking-make-sense-fit-bayesian-hierarchical-models-instead-frequentist-random-effects/)
- [David Blei on BHM](https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/hierarchical-models.pdf)
- [How hierarchical models improve point estimates of model parameters at the individual level](https://www.sciencedirect.com/science/article/pii/S0022249616300025)


# OLD POST
In this post I attempt to answer the question: "what really makes hierarchical models more flexible than non-hierarchical models?". The concept seems relatively straightforward on the surface. Also, if we want a more flexible model, can't we just use flat priors? What's the secret hierarchical sauce?

May need to use a more complex dataset than just simple linear regression. I will need to find a problem where an MCMC struggles to find an appropriate solution with a single prior, but works well with a hierarchical prior.

### Hierarchical Models

In a Bayesian setting, a hierarchical model induces a "hierarchy" into the priors. All this means in practice is that what would have been a fixed parameter in a prior will now come from a distribution.
Consider a prior on some parameter, $\beta \sim N(\mu, \sigma^2)$. In a non-hierarchical setting, we set values for $\mu$ and $\sigma$, however in a hierarchical setting, we place priors on $\mu$ and/or $\sigma$. For example:

$$ \mu \sim f(\alpha) $$
$$ \sigma \sim g(\theta) $$
$$ \beta \sim N(\mu, \sigma^2) $$

So what does this give us? Why would we / should we use a hierarchical model over a non-hierarchical model?

### Why use hierarchical models?

There are a couple different settings where we'll use a hierarchical model, one of the most common is a random effects model (or mixed effects or multilevel models), where the need for hierarchy is to share data between cohorts. Read more [here](https://web.stanford.edu/class/psych252/section/Mixed_models_tutorial.html).

Hierarchical models are most appropriate when we suspect some hierarchy in the data generation process. For example, if we're analyzing grades of students across multiple schools in a country, it would be naive to assume that all classes/schools/regions are the same. This is an example of hierarchical structure in data, students come from schools, which come from regions. 

Three main reasons why we can choose to use a hierarchical model:

1) There is some dependence in the data that isn't necessarily captured by our covariates. For example sampling people from different communities is not independent as individuals in the same community will likely be more similar than individuals across communities. This dependence changes how we consrtuct our likelihood, as the construction of the likelihood assumes data is gathered independently, which is why we can naively multiply the likelihood density. **is this data sharing?**
2) We may believe that the data itself comes from a hierarchy. For example, students come from classes, which are in schools, which are in communities, etc. Modelling students across different classes can be problematic as there is dependence on the environmental context of the class.
3) Finally, we may want to use hierarchical priors to induce flexibility into the model. Although the change is subtle, it changes the posterior enough to yeild different results.

One purpose is methodological; the other is substantive. Methodologically, when units of analysis are drawn from clusters within a population (communities, neighborhoods, city blocks, etc.), they can no longer be considered independent. Individuals who come from the same cluster will be more similar to each other than they will be to individuals from other clusters. Therefore, unobserved variables may induce statistical dependence between observations within clusters that may be uncaptured by covariates within the model, violating a key assumption of maximum likelihood estimation as it is typically conducted when independence of errors is assumed. Recall that a likelihood function, when observations are independent, is simply the product of the density functions for each observation taken over all the observations. However, when independence does not hold, we cannot construct the likelihood as simply. Thus, one reason for constructing hierarchical models is to compensate for the biases—largely in the standard errors—that are introduced when the independence assumption is violated.

In addition to the methodological need for hierarchical models, substantively we may believe that there are differences in how predictors in a regression model influence an outcome of interest across clusters, and we may wish to model these differences. In other words, the influence of predictors may
be context-dependent, a notion that is extremely important and relevant to a social scientific understanding of the world. For example, the emergence of hierarchical modeling in education research occurred because there is a natural nesting of students within classes and classes within schools, schools within communities, and so on, and grades, test performance,
etc. may be dependent on teacher quality, making students in one class different from those in another class. In other words, student performance may be dependent on the teacher—the environmental context of classes.

### Pooling the Right Way 

I won't go into detail about using hierarchical models to pool data, as there are many great blog posts about that. However I'll briefly walk through an example where pooling is necessary. 

Other great posts that talk about this use of hierarchical models are:  

- [Best of both worlds: Hierarchical models](https://twiecki.io/blog/2014/03/17/bayesian-glms-3/)
- [Radon data analysis](https://github.com/fonnesbeck/multilevel_modeling/blob/master/multilevel_modeling.ipynb)
- [Shrinkage in hierarchical models](http://doingbayesiandataanalysis.blogspot.com/2012/11/shrinkage-in-multi-level-hierarchical.html)


### Posterior Overhaul 

Hierarchical models also work because the resulting posterior is changed completely. I'll demonstrate that in this section and walk through an example using a non-hierarchical and a hierarchical model. 

### Open Questions

- **Hierarchical priors make the model more flexible. Why can't we just use a flat prior for added flexibility?** - Two main things here, hierarchical models allow you to pool data from different classes without making naive assumptions about the classes (is this a random effects model?). Second: in general can we just use flatter priors? Or should they be conjugate? Is it because of the resulting posterior?  

- Specifically in the case of Normal-InverseChiSquared, the resulting posterior distribution is t-distributed, which has heavier tails than just a Normal. How will using a Normal-InverseChiSquared hierarchical prior compare to using a non-hierachical prior with fat tails? What if we just use a t-distributed prior? For this maybe we can try the 8 schools model with a prior with fat tails?

- I want to compare these 3 prior specs on an appropriate problem. Appropriate meaning not too simple:
  - Normal prior
  - Flat prior, to try to induce flexibility without hierarchy
  - Hierarchical prior

- In addition to the added flexibility, hierarchical models also help with data pooling. For example in 8 schools.

The $t_{\nu}(\mu, \sigma^2)$ distribution can be represented with a Gaussian with mean $\mu$ and variance term distributed as an Inverse-$\chi^2$ with $\nu$ degrees of freedom -->

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2021/01/29/hierarchical-models/</guid>
                <description>
                    
                    Exploring pooling and hierarchical models with Numpyro by estimating the free throw percentage of NBA players
                    
                </description>
                <pubDate>Fri, 29 Jan 2021 02:22:00 -0500</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
        
            <item>
                <title>Gaussian Processes and Regression</title>
                <link>http://localhost:4000/2021/01/05/gaussian-processes/</link>
                <content:encoded>
                    <![CDATA[
                    <p>I’ve found many articles about Gaussian processes that start their explanation by describing stochastic processes, then go on to say that a GP is a distribution over functions, or an infinite dimensional distribution, etc. etc. I find these harsh for an introduction, so in this post I try to explain GPs in a more approachable manner. Then I talk about Gaussian process regression and its relationship with Bayesian linear regression, with a simple example using GPyTorch.</p>

<p> </p>

<h3 id="how-to-start-thinking-about-a-gaussian-process">How to start thinking about a Gaussian Process?</h3>

<p>We can start by building multivariate Gaussians from univariate Gaussians. With a single random variable, $X_1 \sim N(\mu_1, \sigma_1^2)$, we can append $X_2 \sim N(\mu_2, \sigma_2^2)$ to get the vector $(X_1, X_2)$. If $X_1$ and $X_2$ have covariance $\sigma_{12}$, this vector will have distribution:</p>

\[\begin{pmatrix} X_1 \\ X_2 \end{pmatrix} \sim N \left(\begin{bmatrix} \mu_1 \\ \mu_2 \end{bmatrix}, \begin{bmatrix} \sigma_1^2 &amp; \sigma_{12} \\ \sigma_{12} &amp; \sigma_2^2 \end{bmatrix} \right)\]

<p>If we continue appending more Normally distributed random variables, $X_3, X_4, …$ constructing larger multivariate Gaussians is easy, once we have their mean and covariance. Then, this multivariate Gaussian will be fully specified by the mean vector and covariance matrix. To generalize this concept of continuously incorporating Normally distributed RV’s into the same distribution, we need a function to describe the mean and another to describe the covariance.</p>

<p>This is what the Gaussian process provides. It is specified by a mean function, $\mu(x)$ and a covariance function (called the kernel function), $k(x, x’)$, that returns the covariance between two points, $x$ and $x’$. Now we are not limited to $n$ variables for a $n$-variate Gaussians, but can model any amount (possibly infinite) with the GP. We write:</p>

\[f(x) \sim GP(\mu(x), k(x, x'))\]

<p>The kernel function, $k(x, x’)$ is simply a measure of how similar $x$ and $x’$ are, and an exmaple of one is the squared exponential kernel:</p>

\[k(x, x') = \sigma^2 \exp(-\frac{(x - x')^2}{2l^2})\]

<p>This is a loose intro to GP’s to convey the interpretation of “infinite dimensional” and “distribution over functions”. The book <a href="http://gaussianprocess.org/gpml/chapters/RW.pdf">Gaussian Processes for Machine Learning</a> goes into detail.</p>

<p> </p>

<h3 id="samples-from-a-gaussian-process-prior">Samples from a Gaussian Process Prior</h3>

<p>Since the Gaussian process is essentially a generalization of the multivariate Gaussian, simulating from a GP is as simple as simulating from a multivariate Gaussian. The steps are below:</p>

<ul>
  <li>Start with a vector, $x_1, x_2, …, x_n$ that we will build the GP from. This can be done in Python with <code class="language-plaintext highlighter-rouge">np.linspace</code>.</li>
  <li>Choose a kernel, $k$, and use it to calculate the covariance matrix for each combination of $(x_i, x_j)$. We should end up with a matrix of dimension $(n, n)$. This is the covariance matrix for the multivariate Gaussian we are sampling from. We’ll use a zero-vector for its mean</li>
  <li>The resulting sample paths from this multivariate Gaussian are realizations of the Gaussian process, $GP(0, k)$. We can plot these values and a 95% confidence interval by taking the mean $\pm$ 1.96.</li>
</ul>

<p>Code to do this is below:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kernel</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">*</span> <span class="n">RBF</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">n</span> <span class="o">=</span> <span class="mi">100</span> 
<span class="n">n_func</span> <span class="o">=</span> <span class="mi">7</span> <span class="c1"># number of functions to sample from the GP 
</span><span class="n">L</span> <span class="o">=</span> <span class="o">-</span><span class="mi">5</span><span class="p">;</span> <span class="n">U</span> <span class="o">=</span> <span class="mi">5</span>

<span class="c1"># start with X = (x_1, x_2, ..., x_n)
</span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">L</span><span class="p">,</span> <span class="n">U</span><span class="p">,</span> <span class="n">n</span><span class="p">).</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="c1">#  use kernel to calculate the covariance matrix
</span><span class="n">K</span> <span class="o">=</span> <span class="n">kernel</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

<span class="c1"># parametize a multivariate Gaussian with zero mean and K as the covariance matrix
</span><span class="n">ys</span> <span class="o">=</span> <span class="n">multivariate_normal</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> 
                             <span class="n">cov</span> <span class="o">=</span> <span class="n">K</span><span class="p">,</span> 
                             <span class="n">size</span> <span class="o">=</span> <span class="n">n_func</span><span class="p">)</span>
</code></pre></div></div>

<div class="figure" align="center">
    <img src="/assets/gp_prior_samples.png" width="70%" height="70%" />
    <div class="caption" width="70%" height="70%">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> 7 samples from a Gaussian process prior, along with a 95% confidence interval. Each curve is the result of sampling from a multivariate Gaussian with $n=100$ variables. If we reduce $n$, the samples will look less and less smooth, until $n=2$, where the sample will just be a line. </p>
    </div>
</div>

<p> </p>

<h3 id="gaussian-process--regression">Gaussian Process + Regression</h3>

<p>Nothing so far is groundbreaking, or particularly useful. All we have done is explained a way of generalizing the multivariate Normal, but haven’t talked about how it can be used in real life. However, you could imagine that starting with a prior over functions, we can form a posterior, $p(f \mid X, y)$ by conditioning on our data. Intiutively, doing this excludes all functions that don’t “pass through” our data, $(X, y)$.</p>

<p>I’ll approach Gaussian process regression from a slightly different perspective in this section, building up from Bayesian linear regression. This is a cool approach I found in David MacKay’s <a href="http://www.inference.org.uk/mackay/itila/book.html">book</a>, that I haven’t seem much elsewhere.</p>

<p>To set the stage, we are interested in modelling a function, $f$, for which we have data, $(X, y)$. We start with a <a href="https://xavierbourretsicotte.github.io/Kernel_feature_map.html">feature map</a> for the input, $R = \phi(X)$, so that $R$ an $N \times D$ matrix. Then $y = Rw$ and we can assign priors, $p(w)$, to build a posterior distribution for the weights, $p(w \mid y, X)$. This posterior is used to make future predictions and recreate $f = y + \epsilon$.</p>

\[p(w \mid y_N, X_N) = \frac{p(y_N \mid X_N, w) p(w)}{p(y_N \mid X_N)}\]

<p>However, in some cases we’re only interested in making predictions, and in a Bayesian setting this boils down to 2 distributions: (1) the posterior predictive distribution in order to actually make a prediction and (2) the marginal likelihood for model comparison.</p>

\[\text{Posterior predictive: } p(y_{n+1} \mid y_N, X_N)\]

\[\text{Marginal likelihood: } p(y_{N} \mid X_N)\]

<p>Expanding the formulations from Bayesian linear regression:</p>

\[y = Rw \qquad \qquad \text{where: } w \sim N(0, \sigma_w^2)\]

<p>And since $y$ is a linear function of $w$ (which is a Normally distributed random variable), its prior is:</p>

\[y \sim N(0, \sigma_w^2 RR^T)\]

<p>Accounting for noise in our observations, $\sigma^2_{err}$ the prior on our function, $f$, is:</p>

\[f \sim N(0, \sigma_w^2 RR^T + \sigma^2_{err} I)\]

<p>This is how the Gaussian process is a prior over functions. The kernel described in that section is exacly $RR^T = \phi(X)\phi(X)^T$ in this section. Now we can start to create the posterior predictive distribution and marginal likelihood.</p>

<p>Before we get to the practical stuff, a note about kernels. There are many ways to get confused when first learning about kernels. What helped me is first understanding that a kernel is just a function that accepts 2 inputs and returns how “close” the inputs are to each other. From there, you can go in any direction exploring them, some good articles are: <a href="https://www.cs.toronto.edu/~duvenaud/cookbook/">here</a>, <a href="http://mlg.eng.cam.ac.uk/tutorials/06/es.pdf">here</a> and <a href="https://statisticaloddsandends.wordpress.com/2019/06/28/common-covariance-classes-for-gaussian-processes/">here</a>.</p>

<p> </p>

<h4 id="simulation-problem">Simulation Problem</h4>

<p>In the first couple sentences of the last section I mentioned that we can condition the GP prior on the observed data to get a posterior distribution. All the observed data will then pass through this posterior distribution over functions. This section will use GP’s to extrapolate a simulated function. We don’t account for noisy observations, which is of course a terrible assumption in the real world.</p>

<p>I’ll use <a href="https://gpytorch.ai/">GPyTorch</a> for inference. This is sort of like using a Ferrari to get groceries but GPyTorch looks promising, especially with Pytorch integration. Both <a href="https://docs.pymc.io/Gaussian_Processes.html">PyMC3</a> and <a href="https://scikit-learn.org/stable/modules/gaussian_process.html">sklearn</a> have easy-to-use implementations.</p>

<p>Here’s the function we want to approximate. The points in red are the training data, and we will try to approximate the blue section using a GP.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">g</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">vectorize</span><span class="p">(</span><span class="k">lambda</span> <span class="n">y</span><span class="p">:</span> <span class="n">math</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">0.4</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span><span class="o">*</span><span class="n">math</span><span class="p">.</span><span class="n">sin</span><span class="p">(</span><span class="mi">4</span><span class="o">*</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="n">math</span><span class="p">.</span><span class="n">log</span><span class="p">(</span><span class="nb">abs</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">750</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">4.01</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span>
<span class="n">test_x</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>

<span class="n">train_y</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">train_x</span><span class="p">)</span> 
<span class="n">test_y</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span> 
<span class="n">train_y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">train_y</span><span class="p">)</span>
<span class="n">test_y</span><span class="o">=</span><span class="n">torch</span><span class="p">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">test_y</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">dpi</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'red'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Train set"</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">'blue'</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s">"Test set"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Observed and test data"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">();</span>
</code></pre></div></div>

<!-- <p align="center">
  <img src="/assets/exactGP_simulated_function.png" width="70%" height="70%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/exactGP_simulated_function.png" width="65%" height="65%" />
    <div class="caption" width="70%" height="70%">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Simulated function we are interested in modelling with a GP. We will take samples from the red section and see how well the GP can recreate the blue section </p>
    </div>
</div>

<p> </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ExactGP</span><span class="p">(</span><span class="n">gpytorch</span><span class="p">.</span><span class="n">models</span><span class="p">.</span><span class="n">ExactGP</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ExactGP</span><span class="p">,</span> <span class="bp">self</span><span class="p">).</span><span class="n">__init__</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">mean_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">means</span><span class="p">.</span><span class="n">ConstantMean</span><span class="p">()</span> <span class="c1"># mean
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">covar_module</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">kernels</span><span class="p">.</span><span class="n">ScaleKernel</span><span class="p">(</span><span class="n">gpytorch</span><span class="p">.</span><span class="n">kernels</span><span class="p">.</span><span class="n">RBFKernel</span><span class="p">())</span> <span class="c1"># kernel
</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">mean_x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">mean_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
        <span class="n">covar_x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">covar_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> 
        <span class="k">return</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">distributions</span><span class="p">.</span><span class="n">MultivariateNormal</span><span class="p">(</span><span class="n">mean_x</span><span class="p">,</span> <span class="n">covar_x</span><span class="p">)</span>

<span class="c1"># initialize likelihood and model
</span><span class="n">likelihood</span> <span class="o">=</span> <span class="n">gpytorch</span><span class="p">.</span><span class="n">likelihoods</span><span class="p">.</span><span class="n">GaussianLikelihood</span><span class="p">()</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ExactGP</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">,</span> <span class="n">likelihood</span><span class="p">)</span>
</code></pre></div></div>

<p> </p>

<!-- <p align="center">
  <img src="/assets/squared_exp_kernel_posterior.png" width="100%" height="70%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/squared_exp_kernel_posterior.png" width="90%" height="90%" />
    <div class="caption">
        <p> Posterior distribution after fitting the data in red. The graph on the left shows the confidence interval for the test set (blue region). As we get further and further away from the observed data, the confidence band grows. The graph on the right shows samples from the posterior distrubtion. Because we condition on the data and don't add noise, we are forcing the posterior to "pass through" every single one of our observed datapoints.  </p>
    </div>
</div>

<!-- ### Questions

- How are the weights, $w$ integrated out when doing inference on a GP?
- Can I use GPyTorch for a text classification model with TF-IDF features?
- What does it mean to "fit a Gaussian process"? What is actually going on in the background? I don't understand how we can simulate draws from the prior.
- Imagine points on a line. If we divide the line into 5 equal points and each point is Normally distributed, this is what a multivariate gaussian would look like, however if we wanted every single one of the points on the line to be normally distributed, this is what a guassian process would look like.
- Can I make an active learner using a GP and the embeddings from a NN to learn  -->

<!-- ## A Note on Regression

Let's start by explaining different types of linear regression. In simple linear regression, we first make a linearity assumption about the data (we assume the target variable is a linear combination of the features), then we estimate model parameters based on the data. In Bayesian linear regression, we make the same linearity assumption, however we take it a step further and make an incorporate beliefs about the parameters into the model (priors), then learn the parameters from the data.
Gaussian Process Regression takes a different approach. We don't drop the linearity assumption, and the priors on the parameters. Instead we put a prior on **_all possible models_**. As we observe data, the posterior.

**What is Gaussian Process Regression?** - In Gaussian Process regression, a GP is used as a prior on $f$. This means that the posterior distribution over functions is also a GP. The posterior has to be updated every time we observe new data, because the specification of the posterior depends on observed data. Intuitively, the reason we update the GP is to eleminate all functions that do not pass through the observed data points.

### Notes

- The GP is a prior over functions. It is a prior because we specify that we want smooth functions, and we want our points to be related in a certain way, which we do with the kernel. -->

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2021/01/05/gaussian-processes/</guid>
                <description>
                    
                    A explanation of Gaussian processes and Gaussian process regression, starting with simple intuition and building up to inference. I sample from a GP in native Python and test GPyTorch on a simple simulated example.
                    
                </description>
                <pubDate>Tue, 05 Jan 2021 19:22:00 -0500</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
        
            <item>
                <title>Dealing with Overconfidence in Neural Networks: Bayesian Approach</title>
                <link>http://localhost:4000/2020/07/29/overconfident-nn/</link>
                <content:encoded>
                    <![CDATA[
                    <p>I trained a multi-class classifier on images of cats, dogs and wild animals and passed an image of myself, it’s 98% confident I’m a dog. The problem isn’t that I passed an inappropriate image, because models in the real world are passed all sorts of garbage. It’s that the model is overconfident about an image far away from the training data. Instead we expect a more uniform distribution over the classes. The overconfidence makes it difficult to post-process model output (setting a threshold on predictions, etc.), which means it needs to be dealt with by the architecture.</p>

<p>In this post I explore a Bayesian method for dealing with overconfident predictions for inputs far away from training data in neural networks. The method is called last layer Laplace approximation (LLLA) and was proposed in <a href="https://arxiv.org/abs/2002.10118">this</a> paper published in ICML 2020.</p>

<p> </p>

<h3 id="why-is-this-a-problem">Why is this a problem?</h3>

<p>You might argue that since I only trained the classifier on animals, of course it breaks when you show it a human, and you’re right. However, in real world systems, we aren’t able to filter out animal images from non-animal images before sending it to the model, so we need it to be robust to garbage input. The animal-human example tries to replicate this on a small scale (one image). Properly quantifying uncertainty is important because we (as practitioners training the models) can’t be confident in the model’s ability to generalize if it assigns arbitrarily high confidence to garbage input.</p>

<p> </p>

<h3 id="softmax-classifier">Softmax Classifier</h3>

<p>The 3-class classifier was trained on images of cats, dogs and wild animals taken from Kaggle that can be downloaded <a href="https://www.kaggle.com/andrewmvd/animal-faces?">here</a>.</p>

<!-- <p align="center">
  <img src="/assets/overconfident-NN-training-data.png" width="70%" height="70%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/overconfident-NN-training-data.png" width="85%" height="85%" />
    <div class="caption">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
    </div>
</div>

<p> </p>

<p>The model used was Resnet-18, which yields ~99% accuracy on the validation set. Only using this for evaluation would have us believe it’s an amazing model, but that’s not why we’re here. Below is the image of myself and a dog, where apparently I’m more dog than this actual dog. Even worse, it’s 98% confident that I’m a dog, so I’d be a dog even if we were only considering predictions with over 95% confidence.</p>

<p> </p>

<!-- <p align="center">
  <img src="/assets/overconfident-NN-softmax-predictions.png" width="90%" height="90%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/overconfident-NN-softmax-predictions.png" width="85%" height="85%" />
    <div class="caption">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Parsed an image of myself through the animal network and it's 98% confident I'm a dog. 
        </p>
    </div>
</div>

<p> </p>

<h3 id="possible-solutions">Possible Solutions</h3>

<p><a href="https://arxiv.org/pdf/1812.05720.pdf">This paper</a> proposes a nice explanation and proof for the over-confidence of out-of-distribution examples in ReLU networks. Essentially, they prove that for a given class $k$, there exists a scaling factor $\alpha &gt; 0$ such that the softmax value of input $\alpha x$ as $\alpha \to \infty$ is equal to 1. This means that there are infinitely many inputs that obtain arbitrarily high confidence in ReLU networks. A bi-product of which is the inability to set softmax thresholds to preserve classifier precision.</p>

<p>There are a couple of ways to approach this, which broadly fall into two categories: 1) building a generative model for the data (VAE, GAN, etc.) or 2) changing the structure of the network. The generative approach doesn’t really solve the problem with ReLU networks. There’s a great <a href="https://emiliendupont.github.io/2018/03/14/mnist-chicken/">Chicken-MNIST</a> blog post that discusses a potential solution using VAEs. Another approach, that would fall into the category of changing the network structure is to change the loss function, which was done in <a href="https://arxiv.org/pdf/1812.05720.pdf">this paper</a>. Instead, we’ll opt for changing the network by putting a posterior over the weights of the last layer, as decsribed in <a href="https://arxiv.org/abs/2002.10118">this paper</a>.</p>

<p> </p>

<h3 id="last-layer-bayesian-ness">Last Layer Bayesian-ness</h3>

<p>Bayesian methods are great for quantifying uncertainty, and that’s what we want in this case. The problem is that this model, and all other deep learning models, have way too many parameters to have an appropriate posterior over all. <strong>The proposed solution is to only have a posterior over the weights in the last layer.</strong> This is perfect for implementation because we can in theory have the best of both worlds - first use the ReLU network as a feature extractor, then a Bayesian layer at the end to quantify uncertainty.<br />
The posterior over the last layer weights can be approximated with a <a href="http://www2.stat.duke.edu/~st118/sta250/laplace.pdf">Laplace approximation</a> and can be easily obtained from the trained model with Pytorch autograd.</p>

<p>Amazingly, the only parameter we have to focus on is $\sigma^2_0$, the variance of the prior on the weights. It governs how conservative the predictions are. As $\sigma^2_0$ increases, the confidence of out-of-distribution predictions decreases, which is what we want. However we cannot naively increase $\sigma^2_0$ as making it too large would cause predictions for images close to the training data to be uniform as well. Decreasing $\sigma^2_0$ causes the predictions to be more and more similar to the softmax predictions. We want a balance between the two extremes.</p>

<p>Now we can use the last layer Laplace approximation to see if it helps the overconfidence issue. Below I ran the same images of myself and the dog through both the model using softmax and last layer Laplace. I’m still a dog, but with much lower confidence, allowing us to potentially set a threshold on the output.</p>

<p> </p>

<!-- <p align="center">
  <img src="/assets/overconfident-NN-out-of-sample-predictions.png" width="90%" height="90%">
</p> -->
<div class="figure" align="center">
    <img src="/assets/overconfident-NN-out-of-sample-predictions.png" width="85%" height="85%" />
    <div class="caption">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Comparison of outputs from using LLLA and Softmax. The scores seem to be muted with LLLA, so we have to explore whether this happens across the board or only for one image.
        </p>
    </div>
</div>

<p> </p>

<h3 id="animal-model--animal-data">Animal Model + Animal Data</h3>

<p>So far we’ve only tested the method with two hand selected images. I want to see if this method just scales down all confident predictions, or if it is doing some interesting stuff under the hood. To start more evaluation, we’ll plot the confidence level of the top class for the validation data (all animal images, no garbage).</p>

<p> </p>

<!-- <p align="center">
  <img src="/assets/overconfident-NN-top-class-prob-distribution.png"  width="90%" height="90%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/overconfident-NN-top-class-prob-distribution.png" width="85%" height="85%" />
    <div class="caption">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Comparison of the top class score for the animal data test set using LLLA and Softmax. There are no out-of-distribution images here, so it's difficult to say how concerning this is.
        </p>
    </div>
</div>

<p> </p>

<p>The softmax model is really confident about nearly all the images in the validation set, whereas the LLLA model has a flatter confidence distribution. Can’t stop now! When does the LLLA model produce high or low confidence predictions?<br />
It’s difficult to come to a general conclusion on this, but interestingly the LLLA model can produce predictions with both high and low confidence even when the softmax prediction confidence is high.</p>

<p align="center">
  <img src="/assets/overconfident-NN-LLLA-high-conf.png" width="75%" height="75%" />
</p>

<p align="center">
  <img src="/assets/overconfident-NN-LLLA-low-conf.png" width="75%" height="75%" />
</p>
<p> </p>

<h3 id="animal-model--simpsons-data">Animal Model + Simpsons Data</h3>

<p>Last thing - what’s the confidence distribution for images that are completely different. This should give us a proxy for how both methods deal with complete garbage thrown at them. As discussed before, this is the problem ML models in the wild face - you train them to learn specific patterns and send them into the deep end where they have to deal with completely unseen data.</p>

<p align="center">
  <img src="/assets/overconfident-NN-simpsons-data.png" width="70%" height="70%" />
</p>

<p>I passed 300 of these Simpsons character faces into the classifier and plotted the confidence level of the top class for both LLLA and softmax models. Again, since these are garbage images, we’d expect this distribution to be closer to $0.33$ (random chance). Keep in mind the confidence will never drop below $0.33$ as we’re only looking at the top class.</p>

<p> </p>

<!-- <p align="center">
  <img src="/assets/overconfident-NN-top-class-prob-out-out-distribution.png" width="90%" height="90%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/overconfident-NN-top-class-prob-out-out-distribution.png" width="85%" height="85%" />
    <div class="caption">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Distribution of top-class scores (probabilities) using Simpsons characeters on our animal classifier. This plot is concerning as many of Simpsons characters have been predicted as an animal with high probability. The LLLA scores (right) here are much more reasonable.
        </p>
    </div>
</div>

<p>These results are pretty alarming for the softmax classifier. The majority of Simpson faces are predicted as cat/dog/wild with probability greater than $0.8$ with the softmax classifier, whereas there are no predictions with greater than $0.5$ confidence from the LLLA classifier. This is amazing!</p>

<p> </p>

<h3 id="confidence-threshold">Confidence Threshold</h3>

<p>All of this would be for nothing if the model metrics aren’t preserved after post-processing the output. The simplest way to test this is to examine the tradeoff between a confidence threshold and model accuracy. I’ve taken the validation set, which are appropriate inputs for the classifier, and plotted the model accuracy at different thresholds.</p>

<p> </p>

<p align="center">
  <img src="/assets/overconfident-NN-threshold-plot.png" width="75%" height="75%" />
</p>

<p>Even with a threshold value of $0.5$, the LLLA model is more than 95% accurate on the validation set. In addition, using the $0.5$ threshold with the LLLA model excludes all Simpsons characters discussed in the previous section, whereas the softmax model will be mostly unchanged.</p>

<p> </p>

<h3 id="conclusion">Conclusion</h3>

<p>From the light experimentation done here, the last layer Laplace approximation seems to be a good solution to the overconfidence problem. Of course its usage will depend on the specific problem and allowable tradeoff between precision and recall for each class, however these results are promising nonetheless. The icing on the LLLA cake is its ease of implementation and seamless integration with transfer learning.</p>

<p>All the code used in this blog can be found <a href="https://www.kaggle.com/jramkiss/overconfident-neural-networks">here</a>.</p>


                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2020/07/29/overconfident-nn/</guid>
                <description>
                    
                    I trained a classifier on images of animals and gave it an image of myself, it's 98% confident I'm a dog. This is an exploration of a possible Bayesian fix. Code available too
                    
                </description>
                <pubDate>Wed, 29 Jul 2020 12:22:00 -0400</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
        
            <item>
                <title>Notes on the Beta and Dirichlet Distributions</title>
                <link>http://localhost:4000/2020/05/15/beta-and-dirichlet-distributions/</link>
                <content:encoded>
                    <![CDATA[
                    <p>This post motivates the Beta and Dirichlet distributions using a simple example. It also relates the Beta and Dirichlet distributions to the Binomial and Multinomial. It’s written without any equations for readability.</p>

<p>Throughout the post, we’ll use probability distributions to model people’s favourite color. The favourite color experiments start off very simple, then get more interesting as we introduce more flexible probability distributions. Then we briefly touch on how the Dirichlet distribution works.</p>

<h2 id="binomial-distribution">Binomial Distribution</h2>

<p>The Binomial distribution describes the number of successes in a binary task. It is parametized by the probability of success, $p$, and the number of times the task was completed, $n$.</p>

<p> </p>
<h3 id="example-simple-favourite-colour">Example: Simple Favourite Colour</h3>

<p>Suppose we have an experiment where we ask $n$ random people if their favourite color is blue. The number of people whose favourite colour is blue, follows a Binomial distribution. The parameter $p$ being the probability of someone’s favourite color being blue. Taking $p=0.5$ and $n=1000$, we can sample from this Binomial and each sample is a potential number of people whose favourite color is blue.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">binom</span>

<span class="n">binom_rvs</span> <span class="o">=</span> <span class="n">binom</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">5000</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharex</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">binom_rvs</span><span class="p">,</span> <span class="n">kde</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Samples from a Binomial(n=1000, p=0.5)"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"Number of Successes"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Density"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([]);</span>
</code></pre></div></div>

<!-- <p align="center">
  <img src="/assets/binomial-samples.png" width="55%" height="55%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/binomial-samples.png" width="70%" height="70%" />
    <div class="caption" width="70%" height="70%">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Histogram of samples from a Binomial(n=1000, p=0.5) distribution. The mean of this distribution is 500, so we expect histogram to be centered around 500, which it is. This of course corresponds to an average of 500 successes over 1000 tries, with a probability of success of 0.5 </p>
    </div>
</div>

<p> </p>

<h2 id="beta-distribution">Beta Distribution</h2>

<p>In a Bayesian setting, we’ll want to use the Binomial distribution as the likelihood for the favourite color problem mentioned above. This would mean placing a prior on $p$, which is a probability and needs to be between $[0, 1]$. It’s possible to use any probability density whose domain is $[0,1]$, however we prefer a distribution that would leave us with an analytic posterior. For a Binomial likelihood this is the Beta distribution, meaning Beta is a conjugate prior for the Binomial.</p>

<p>Samples from the Beta distribution can be thought of as potential probabilities of success, $p$, for the Binomial. The Beta distribution itself is parameterized by $(\alpha, \beta)$ which determine its location and scale. Below are plots of samples from the Beta distribution with different parameters, notice that all the samples are between $(0, 1)$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>

<span class="n">n</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mf">5e5</span><span class="p">)</span> <span class="c1"># number of samples
</span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">beta</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">),</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
<span class="c1">#             color="r",
</span>             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]).</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Samples from Beta(2,2)"</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">beta</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">),</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]).</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Samples from Beta(4, 4)"</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">beta</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">),</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]).</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Samples from Beta(2, 4)"</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">beta</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="n">n</span><span class="p">),</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]).</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Samples from Beta(4, 2)"</span><span class="p">);</span>

</code></pre></div></div>

<!-- <p align="center">
  <img src="/assets/beta-samples.png" width="70%" height="70%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/beta-samples.png" width="70%" height="70%" />
    <div class="caption" width="70%" height="70%">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Plots for 4 different specifications of the Beta distribution. Notice on the x-axis that the support is between [0, 1] </p>
    </div>
</div>
<p> </p>

<h2 id="multinomial-distribution">Multinomial Distribution</h2>

<p>A limitation of the Binomial distribution is we only have 2 potential outcomes. The Multinormial distribution is a generalization of this, so we can have $k$ possible outcomes. It is parameterized by the number of trials, $n$ and the probability of success for each outcome $p_i$. Each sample from a Multinomial is a vector of length $k$, where each index corresponds to the number of successes for that outcome.</p>

<p> </p>

<h3 id="example-favourite-colour">Example: Favourite Colour</h3>

<p>We used the Binomial distribution to find out if people’s favourite colour is blue, but this didn’t give us much information on what other colours people liked.
Now we want more information. We’re interested in the distribution of people whose favourite colours are either: blue, green, red or yellow. If we ask $n$ people to choose their favourite color from one of these, the number of successes for each colour will follow a Multinomial distribution. Each parameter, $p_{blue}, p_{green}, p_{red}, p_{yellow}$ is the probability of that colour being a random person’s favourite. Sampling from this Multinomial will return a vector of length $4$ corresponding to the number of successes for that color. For each sample, the total number of successes sums to $n$.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">multinomial</span>

<span class="n">_p</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.15</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]</span>
<span class="n">multinom_rvs</span> <span class="o">=</span> <span class="n">multinomial</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">n</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">_p</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">sharex</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">multinom_rvs</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Class 1"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">multinom_rvs</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Class 2"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">multinom_rvs</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Class 3"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">multinom_rvs</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> 
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Class 4"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">}).</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Multinomial Samples for class 4, p=[0.1, 0.15, 0.25, 0.5]"</span><span class="p">);</span>
</code></pre></div></div>

<!-- <p align="center">
  <img src="/assets/multinomial-samples.png" width="70%" height="70%">
</p> -->
<div class="figure" align="center">
    <img src="/assets/multinomial-samples.png" width="70%" height="70%" />
    <div class="caption" width="70%" height="70%">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Histogram of samples from a Multinomial distribution with 4 classes, and probabilities: [0.1, 0.15, 0.25, 0.5]. </p>
    </div>
</div>

<p> </p>

<h2 id="dirichlet-distribution">Dirichlet Distribution</h2>

<p>Similarly with the Beta and Binomial combo, we need a prior for each $p_i$ in the Multinomial likelihood. Unlike the Binomial, where we could potentially use any distribution with $(0, 1)$ domain as a prior for $p$, the Multinomial has an added restriction, as the vector of probabilities needs to sum to 1. Placing an arbitrary prior on each $p_i$ won’t ensure that $\sum p_i = 1$. This is what the Dirichlet distribution offers. It acts as a prior over the entire vector of probabilities, $p = [p_1, p_2, …, p_k]$. It is a generalization of the Beta distribution, and is also a conjugate prior for the Multinomial, which is an added benefit.</p>

<p>A vector of length $k$ parameterizes the Dirichlet distribution, and the parameters are similar to $(\alpha, \beta)$ for the Beta distribution. Below are samples from 2 Dirichlet distributions with different parameters.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">dirichlet</span>

<span class="n">dirich_samples</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dirichlet</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">15</span><span class="p">],</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">))</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">sharex</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dirich_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
             <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Alpha = 1"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">"teal"</span><span class="p">,</span>
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
             <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dirich_samples</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
             <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Alpha = 5"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">"blue"</span><span class="p">,</span>
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
             <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dirich_samples</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> 
             <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Alpha = 15"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span>
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
             <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Samples from Dir([1, 5, 15])"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">""</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Density"</span><span class="p">)</span>

<span class="n">dirich_samples</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">dirichlet</span><span class="p">.</span><span class="n">rvs</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">7</span><span class="p">],</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">10000</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dirich_samples</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> 
             <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Alpha = 10"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">"teal"</span><span class="p">,</span>
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
             <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dirich_samples</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> 
             <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Alpha = 0.5"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">"blue"</span><span class="p">,</span>
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
             <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">dirich_samples</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> 
             <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Alpha = 7"</span><span class="p">,</span> <span class="s">"shade"</span><span class="p">:</span> <span class="bp">True</span><span class="p">},</span> 
             <span class="n">color</span> <span class="o">=</span> <span class="s">"red"</span><span class="p">,</span>
             <span class="n">hist</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
             <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
             <span class="n">kde</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Samples from Dir([10, 0.5, 7])"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s">"Samples"</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_yticks</span><span class="p">([])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">].</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s">"Density"</span><span class="p">);</span>
</code></pre></div></div>

<!-- <p align="center">
  <img src="/assets/dirichlet-samples.png" width="70%" height="70%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/dirichlet-samples.png" width="85%" height="85%" />
    <div class="caption" width="85%" height="85%">
        <!-- <span class='caption-label'>Figure 1.</span>  -->
        <p> Probability distributions for 2 different Dirichlet distributions, one above and another below. Notice that the support of the entire distribution is [0, 1], similar to the Beta. It cannot be seen on the graph, but each sample in the Dirichlet sums to 1. </p>
    </div>
</div>

<p> </p>

<h3 id="how-do-we-always-sum-to-1">How do we always sum to 1?</h3>

<p>Let’s take a Dirichlet distribution with 5 components, meaning that samples from this distribution will be a vector of length 5, whose sum is 1:</p>

\[X \sim Dir([\alpha_1, \alpha_2, \alpha_3, \alpha_4, \alpha_5])
\notag\]

<p>Two samples from $X$:</p>

\[x_1 = [0.3, 0.15, 0.05, 0.25, 0.25]
\notag\]

\[x_2 = [0.13, 0.17, 0.05, 0.2, 0.45]
\notag\]

<p>Two things are consistent: $\sum_{i=1}^{5} x_i = 1$ and len(x) = $5$. So we can imagine that each sample from a Dirichlet distribution is a literal stick of length 1, that is broken into $5$ sections. Each section (or class) has a length, for example section 2 in $x_1$ has length $0.15$. Each sample can have different lengths for each section. The Dirichlet distribution does is proposes different ways of breaking this stick into 5 pieces. Of course, there is a specific way of breaking the stick to generate samples from the Distribution, which is very aptly named the <a href="https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf">stick breaking construction</a>.</p>

<p>The next logical step from here is to ask the question: why 5 pieces? What if we don’t know how many pieces we want? So really we want a distribution to propose breaking this stick in any way possible, 3 pieces, 100 pieces, 1e10 places. This can be done with a Dirichlet process.</p>

<h3 id="another-view-distribution-over-distributions">Another View: Distribution over Distributions</h3>

<p>Suppose we have an arbitrary experiment with $k$ outcomes, that each happen with probability $p_i$. Every time we repeat this experiment, we get a probability distribution, $p$. Since we have a finite number of outcomes, we can imagine that each $p$ came from some Dirichlet distribution. In this sense, the Dirichlet distribution is a distribution over probability distributions.</p>

<p> </p>

<p>Good resources for further reading:</p>

<ul>
  <li>Great slides on the Beta and Dirichlet distributions with some more math than this post: <a href="https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/dirichlet.pdf">here</a></li>
  <li>Pretty thorough walk through of conjugate priors and the Expoential family: <a href="https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter9.pdf">here</a></li>
  <li>Great notes on Dirichlet processes: <a href="https://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf">here</a></li>
</ul>

<!--
## Resources
- https://people.eecs.berkeley.edu/~jordan/courses/260-spring10/other-readings/chapter9.pdf
- https://www.stats.ox.ac.uk/~teh/research/npbayes/Teh2010a.pdf
- https://people.eecs.berkeley.edu/~stephentu/writeups/dirichlet-conjugate-prior.pdf
- https://www.cs.cmu.edu/~epxing/Class/10701-08s/recitation/dirichlet.pdf
- https://www.gatsby.ucl.ac.uk/~ywteh/research/npbayes/dp.pdf
-->

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2020/05/15/beta-and-dirichlet-distributions/</guid>
                <description>
                    
                    The Beta and Dirichlet distributions are related to each other in a similar way to the Binomial and Multinomial distributions. This post explains the relationship between these 4 distributions using a simple example and some code.
                    
                </description>
                <pubDate>Fri, 15 May 2020 12:22:00 -0400</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
        
            <item>
                <title>Bayesian Changepoint Detection of COVID-19 Cases in Pyro</title>
                <link>http://localhost:4000/2020/04/15/covid-changepoint-analysis/</link>
                <content:encoded>
                    <![CDATA[
                    <h2 id="problem">Problem</h2>

<p>With the current global pandemic and its associated resources (data, analyses, etc.), I’ve been trying for some time to come up with an interesting COVID-19 problem to attack with statistics. After looking at the number of confirmed cases for some counties, it was clear that at <em>some</em> date, the number of new cases stopped being exponential and its distribution changed. However, this date was different for each country (obviously). This post introduces and discusses a Bayesian model for estimating the date that the distribution of new COVID-19 cases in a particular country changes.</p>

<p>An important reminder before we get into it is that all models are wrong, but some are useful. This model is useful for estimating the date of change, not for predicting what will happen with COVID-19. It should not be mistaken for an amazing epidemiology model that will tell us when the quarantine will end, but instead a way of describing what we have already observed with probability distributions.</p>

<p>All the code for this post can be found <a href="https://nbviewer.jupyter.org/github/jramkiss/jramkiss.github.io/blob/master/_posts/notebooks/covid19-changes.ipynb">here</a>.</p>

<h2 id="model">Model</h2>

<p>We want to describe $y$, log of the number of new COVID-19 cases in a particular country each day, as a function of $t$, the number of days since the virus started in that country. We’ll do this using a segmented regression model. The point at which we segment will be determined by a learned parameter, $\tau$. This is model is written below:</p>

<p><strong>Likelihood:</strong></p>

\[\begin{equation*}
  \begin{split}
    y = wt + b + \epsilon
  \end{split}
  \text{, } \qquad \qquad
  \begin{split}
    \epsilon \sim N(0, \sigma^2) \\[10pt]
    p(y \mid w, b, \sigma) \sim N(wt, \sigma^2)
  \end{split}
  \\[15pt]
\end{equation*}\]

\[\begin{equation*}
\begin{split} \text{Where: } \qquad \qquad \end{split}
\begin{split}
w &amp;= \begin{cases}
  w_1 &amp; \text{if } \tau \le t\\
  w_2 &amp; \text{if } \tau \gt t\\
\end{cases} \\
b &amp;= \begin{cases}
  b_1 &amp; \text{if } \tau \le t\\
  b_2 &amp; \text{if } \tau \gt t\\
\end{cases}
\end{split}
\\[10pt]
\end{equation*}\]

<p><strong>Priors:</strong></p>

\[\begin{equation*}
  w_1 \sim N(\mu_{w_1}, \sigma_{w_1}^2) \qquad \qquad
  w_2 \sim N(\mu_{w_2}, \sigma_{w_2}^2)
  \\[10pt]
  b_1 \sim N(\mu_{b_1}, \sigma_{b_1}^2) \qquad \qquad
  b_2 \sim N(\mu_{b_2}, \sigma_{b_2}^2)
  \\[10pt]
  \tau \sim Beta(\alpha, \beta) \qquad \qquad
  \sigma \sim U(0, 3)
\end{equation*}\]

<p> </p>

<p>In other words, $y$ will be modeled as $w_1t + b_1$ for days up until day $\tau$. After that it will be modeled as $w_2t + b_2$.</p>

<p>The model was written in <a href="https://pyro.ai/">Pyro</a>, a probabilistic programming language built on <a href="https://pytorch.org/">PyTorch</a>. Chunks of the code are included in this post, but the majority of code is in <a href="https://nbviewer.jupyter.org/github/jramkiss/jramkiss.github.io/blob/master/_posts/notebooks/covid19-changes.ipynb">this</a> notebook.</p>

<p> </p>

<h2 id="data">Data</h2>

<p>The data used was downloaded from <a href="https://www.kaggle.com/imdevskp/corona-virus-report">Kaggle</a>. Available to us is the number of daily confirmed cases in each country, and Figure 1 shows this data in Italy. It is clear that there are some inconsistencies in how the data is reported, for example, in Italy there are no new confirmed cases on March 12th, but nearly double the expected cases on March 13th. In cases like this, the data was split between the two days.</p>

<p>The virus also starts at different times in different countries. Because we have a regression model, it is inappropriate to include data prior to the virus being in a particular country. This date is chosen by hand for each country based on the progression of new cases and is never the date the first patient is recorded. The “start” date is better interpreted as the date the virus started to consistently grow, as opposed to the date the patient 0 was recorded.</p>

<p> 
<!-- <p align="center">
  <img src="/assets/italy-daily-cases.png" width="90%" height="90%">
</p> --></p>
<div class="figure" align="center">
    <img src="/assets/italy-daily-cases.png" width="90%" height="90%" />
    <div class="caption" width="70%" height="70%">
        <p> Total confirmed COVID-19 cases in Italy on the left and daily cases on the right, from January 1st to March 15th 2020</p>
    </div>
</div>

<p> </p>

<h2 id="prior-specification">Prior Specification</h2>

<p>Virus growth is sensitive to population dynamics of individual countries and we are limited in the amount of data available, so it is important to supplement the model with appropriate priors.</p>

<p>Starting with $w_1$ and $w_2$, these parameters can be loosely interpreted as the growth rate of the virus before and after the date change. We know that the growth will be positive in the beginning and is not likely to be larger than $1$. With these assumptions, $w_1 \sim N(0.5, 0.25)$ is a suitable prior.
We’ll use similar logic for $p(w_2)$, but will have to keep in mind flexibility. Without a flexible enough prior here, the model won’t do well in cases where there is no real change point in the data. In these cases, $w_2 \approx w_1$, and we’ll see and example of this in the <a href="#results">Results</a> section. For now, we want $p(w_2)$ to be symmetric about $0$, with the majority of values lying between $(-0.5, 0.5)$. We’ll use $w_2 \sim N(0, 0.25)$.</p>

<p>Next are the bias terms, $b_1$ and $b_2$. Priors for these parameters are especially sensitive to country characteristics. Countries that are more exposed to COVID-19 (for whatever reason), will have more confirmed cases at its peak than countries that are less exposed. This will directly affect the posterior distribution for $b_2$ (which is the bias term for the second regression). In order to automatically adapt this parameter to different countries, we use the mean of the first and forth quartiles of $y$ as $\mu_{b_1}$ and $\mu_{b_2}$ respectively. The standard deviation for $b_1$ is taken as $1$, which makes $p(b_1)$ a relatively flat prior. The standard deviation of $p(b_2)$ is taken as $\frac{\mu_{b_2}}{4}$ so that the prior scales with larger values of $\mu_{b_2}$.</p>

\[b_1 \sim N(\mu_{q_1}, 1) \qquad \qquad b_2 \sim N(\mu_{q_4}, \frac{\mu_{q_4}}{4})
\notag\]

<p>As for $\tau$, since at this time we don’t have access to all the data (the virus is ongoing), we’re unable to have a completely flat prior and have the model estimate it. Instead, the assumption is made that the change is more likely to occur in the second half of the date range at hand, so we use $\tau \sim Beta(4, 3)$.</p>

<p> </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">COVID_change</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">b1_mu</span><span class="p">,</span> <span class="n">b2_mu</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear1</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear1</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">).</span><span class="n">expand</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]).</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear1</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">b1_mu</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">,</span> <span class="n">bias</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">).</span><span class="n">expand</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]))</span> <span class="c1">#.to_event(1))
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">b2_mu</span><span class="p">,</span> <span class="n">b2_mu</span><span class="o">/</span><span class="mi">4</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">tau</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"tau"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Beta</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"sigma"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">))</span>
        <span class="c1"># fit lm's to data based on tau
</span>        <span class="n">sep</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">tau</span><span class="p">.</span><span class="n">detach</span><span class="p">().</span><span class="n">numpy</span><span class="p">()</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">mean1</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear1</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="n">sep</span><span class="p">]).</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mean2</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear2</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="n">sep</span><span class="p">:]).</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">((</span><span class="n">mean1</span><span class="p">,</span> <span class="n">mean2</span><span class="p">))</span>
        <span class="n">obs</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"obs"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span>
</code></pre></div></div>
<p> </p>

<p><a href="https://www.cs.toronto.edu/~radford/ftp/ham-mcmc.pdf">Hamiltonian Monte Carlo</a> is used for posterior sampling. The code for this is shown below.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">COVID_change</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="n">b1_mu</span> <span class="o">=</span> <span class="n">bias_1_mean</span><span class="p">,</span>
                     <span class="n">b2_mu</span> <span class="o">=</span> <span class="n">bias_2_mean</span><span class="p">)</span>

<span class="n">num_samples</span> <span class="o">=</span> <span class="mi">800</span>
<span class="c1"># mcmc
</span><span class="n">nuts_kernel</span> <span class="o">=</span> <span class="n">NUTS</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">mcmc</span> <span class="o">=</span> <span class="n">MCMC</span><span class="p">(</span><span class="n">nuts_kernel</span><span class="p">,</span>
            <span class="n">num_samples</span><span class="o">=</span><span class="n">num_samples</span><span class="p">,</span>
            <span class="n">warmup_steps</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
            <span class="n">num_chains</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">mcmc</span><span class="p">.</span><span class="n">run</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">mcmc</span><span class="p">.</span><span class="n">get_samples</span><span class="p">()</span>
</code></pre></div></div>

<p> </p>

<h2 id="results">Results</h2>

<p>Since I live in Canada and have exposure to the dates precautions started, modeling will start here. We’ll use February 27th as the date the virus “started”.</p>

<p><strong>Priors:</strong></p>

\[w_1, w_2 \sim N(0, 0.5) \qquad b_1 \sim N(1.1, 1) \qquad b_2 \sim N(7.2, 1)
\notag\]

<p> </p>

<p><strong>Posterior Distributions</strong></p>

<!-- figure 1: daily confirmed cases in Italy -->
<!-- <p align="center">
  <img src="/assets/canada-posterior-plots.png" width="90%" height="90%">
</p> -->

<div class="figure" align="center">
    <img src="/assets/canada-posterior-plots.png" width="90%" height="90%" />
    <div class="caption" width="70%" height="70%">
        <p> Posterior distributions for each parameter in our model using Canada's COVID-19 data. Notice that the posteriors for $w_1$ and $w_2$ don't overlap</p>
    </div>
</div>

<p> </p>

<p>Starting with the posteriors for $w_1$ and $w_2$, if there was no change in the data we would expect to see these two distributions close to each other as they govern the growth rate of the virus. It is a good sign that these distributions, along with the posteriors for $b_1$ and $b_2$, don’t overlap. This is evidence that the change point estimated by our model is true.</p>

<p>This change point was estimated as: <strong>2020-03-28</strong></p>

<p>As a side note, with no science attached, my company issued a mandatory work from home policy on March 16th. Around this date is when most companies in Toronto would have issues mandatory work from home policies where applicable. Assuming the reported incubation period of the virus is up to 14 days, this estimated date change makes sense as it is 12 days after widespread social distancing measures began!</p>

<p>The model fit along with 95% credible interval bands can be seen in the plot below. On the left is log of the number of daily cases, which is what we used to fit the model, and on the right is the true number of daily cases. It is very difficult to visually determine a change point by simply looking at the number of daily cases, and even more difficult by looking at the total number of confirmed cases.</p>

<p> 
<!-- <p align="center">
  <img src="/assets/canada-regression-plot.png" width="90%" height="90%">
</p> --></p>
<div class="figure" align="center">
    <img src="/assets/canada-regression-plot.png" width="90%" height="90%" />
    <div class="caption" width="70%" height="70%">
        <p> Left: log(daily confirmed cases) with the estimated date that the curve started to flatten (March 28th) and the 90% credible interval. Right: Raw data for the daily cases each day, along with a 90% credible interval for the day the curve started to flatten</p>
    </div>
</div>

<p> </p>

<h3 id="assessing-convergence">Assessing Convergence</h3>

<p>When running these experiments, the most important step is to diagnose the MCMCfor convergence. I adopt 3 ways of assessing convergence for this model by observing mixing and stationarity of the chains and $\hat{R}$. $\hat{R}$ is the factor by which each posterior distribution will reduce by as the number of samples tends to infinity. A perfect $\hat{R}$ value is 1, and values less than $1.1$ are indicative of convergence. We observe mixing and stationarity of the Markov chains in order to know if the HMC is producing appropriate posterior samples.</p>

<p>Below are <a href="https://stats.stackexchange.com/questions/120936/why-we-need-trace-plot-for-mcmc-results">trace plots</a> for each parameter. Each chain is stationary and mixes well. Additionally, all $\hat{R}$ values are less than $1.1$.</p>

<p> 
<!-- <p align="center">
  <img src="/assets/canada-trace-plots.png" width="90%" height="90%">
</p> --></p>
<div class="figure" align="center">
    <img src="/assets/canada-trace-plots.png" width="90%" height="90%" />
    <div class="caption" width="70%" height="70%">
        <p> Trace plots and $\hat{R}$ values for all posterior samples, plotten for MCMC diagnostics. </p>
    </div>
</div>
<p> </p>

<p>After convergence, the last thing to check before moving on to other examples is how appropriate the model is for the data. Is it consistent with the assumptions made earlier? To test this we’ll use a residual plot and a QQ-plot, as shown below.
I’ve outlined the estimated change point in order to compare residuals before and after the change to test for homoscedasticity.
The residuals follow a Normal distribution with zero mean, and no have dependence with time, before and after the date of change.</p>

<p> 
<!-- <p align="center">
  <img src="/assets/canada-resid-plots.png" width="90%" height="90%">
</p> --></p>

<div class="figure" align="center">
    <img src="/assets/canada-resid-plots.png" width="90%" height="90%" />
    <div class="caption" width="70%" height="70%">
        <p> Residual and QQ-plots validating our error assumption. </p>
    </div>
</div>
<p> </p>

<h3 id="what-about-no-change">What About no Change?</h3>

<p>To test the model’s robustness to a country that has not began to flatten the curve, we’ll look at data from Canada up until March 28th. This is the day that the model estimated curve flattening began in Canada. Just because there isn’t a true change date doesn’t mean the model will output “No change”. We’ll have to use the posterior distributions to reason that the change date provided by the model is inappropriate, and consequentially there is no change in the data.</p>

<p><strong>Prior</strong></p>

\[w_1, w_2 \sim N(0, 0.5) \qquad b_1 \sim N(0.9, 1) \qquad b_2 \sim N(6.4, 1.6)
\notag\]

<p> </p>

<p><strong>Posterior Distributions</strong></p>

<p> 
<!-- <p align="center">
  <img src="/assets/canada-march27-posterior-plots.png" width="90%" height="90%">
</p> --></p>

<div class="figure" align="center">
    <img src="/assets/canada-march27-posterior-plots.png" width="90%" height="90%" />
    <div class="caption" width="70%" height="70%">
        <p> Posterior plots for parameters after selecting a date range where the COVID-19 curve has not began to flatten. Notice the distributions for $w_1$ and $w_2$ overlap </p>
    </div>
</div>
<p> </p>

<p>The posteriors for $w_1$ and $w_2$ have significant overlap, indicating that the growth rate of the virus hasn’t changed significantly. Posteriors for $b_1$ and $b_2$ are also overlapping. These show that the model is struggling to estimate a reasonable $\tau$, which is good validation for us that the priors aren’t too strong.</p>

<p>Although we have already concluded that there is no change date for this data, we’ll still plot the model out of curiosity.</p>

<p> </p>
<p align="center">
  <img src="/assets/canada-march27-regression-plot.png" width="90%" height="90%" />
</p>
<p> </p>

<p>Similar to the previous example, the MCMC has converged. The trace plots below show sufficient mixing and stationarity of the chains, and most $\hat{R}$ values less than $1.1$.</p>

<p> </p>
<p align="center">
  <img src="/assets/canada-march27-trace-plots.png" width="90%" height="90%" />
</p>
<p> </p>

<h2 id="next-steps-and-open-questions">Next Steps and Open Questions</h2>

<p>This model is able to describe the data well enough to produce a reliable estimate of the day flattening the curve started. An interesting byproduct of this is the coefficient term for the 2nd regression line, $w_2$. By calculating $w_2$ and $b_2$ for different countries, we can compare how effective their social distancing measures were. The logical next modelling step would be to fit a hierarchical model in order to use partial pooling of data between countries.</p>

<p>Thank you for reading, and definitely reach out to me by e-mail or other means if you have suggestions or recommendations, or even just to chat!</p>

<!--
### Notes and Findings - Remove

- With a strong prior on $b_2$, the MCMC converges quickly when we have a change point. If we don't have a change point (Canada before March 29th), some parameters don't converge. This means that the prior is too strong and the model cannot generalize easily. I'll need to do some experiments with the prior specification for $b_2$ to see how flat it should be. Can also experiment with a hierarchical prior on $b_2$. I'm not sure how adding a hierarchical prior will affect the model as we have so little data. UPDATE: Just tried with $\frac{mu_{q_4}}{4}$ and 400 warm-up for Canada before March 29th, everything converged except for $b_2$, which had an R_hat value of 1.2, $w_2$ had an R_hat value of 1.09.
- Interestingly (not really), the model can deal with a flat prior on $b_1$.
- Try flat priors on all parameters. N(0, 5) or something. Assess convergence, R_hat, fit and residuals.


### Open Questions

- Are the reasons for prior specifications reasonable? Specifically want to know about using $mu_{q_1}$ and $mu_{q_4}$, as this in combination with the prior on $\tau$ is a strong assumption that there is a changepoint in the data and possibly making the model subjective.
- How to know if the model is appropriate for the data and models it well?
- Is observing trace plots and R_hat sufficient for convergence?
- In a case like this where we have limited data, how will a hierarchical prior help?
- How to publicize the post?
- Why do some posteriors converge and others don't? Are some parameters notoriously more difficult to learn based on limited data or model specifications? $b_2$ is having a hard time converging with a flatter prior

-->

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2020/04/15/covid-changepoint-analysis/</guid>
                <description>
                    
                    Used Pyro and a Bayesian changepoint model to detect the date that COVID-19 cases started to flattern in different countries.
                    
                </description>
                <pubDate>Wed, 15 Apr 2020 12:22:00 -0400</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
        
            <item>
                <title>Ordinary VS Bayesian Linear Regression</title>
                <link>http://localhost:4000/2020/03/01/regression-vs-bayesian-regression/</link>
                <content:encoded>
                    <![CDATA[
                    <p>Bayesian methods are usually shrouded in mystery, hidden behind pages of math that no practitioner has the patience to understand. Why should I even use this complicated black magic if other models are better? Also, since when is there a Bayesian version of simple linear regression? And while we’re at it, what in the world is <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> and should I even care?</p>

<p>The goal of this post is to answer all these questions and to explain the intuition behind Bayesian thinking without using math. To do this, we’ll fit an ordinary linear regression and a Bayesian linear regression model to a practical problem. The post itself isn’t code-heavy, but rather provides little snippets for you to follow along. I’ve included the notebook with all the code <a href="https://nbviewer.jupyter.org/github/jramkiss/jramkiss.github.io/blob/master/_posts/notebooks/regression_VS_bayesian_regression.ipynb">here</a>.</p>

<h2 id="problem">Problem</h2>

<p><strong>Does business freedom affect GDP the same for European and non-European nations?</strong></p>

<p>This is the problem we want to answer. The data is taken from the <a href="https://www.heritage.org/index/">Heritage Foundation</a> and is as follows:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">business_freedom</code>: Score between 0-100 of a country’s business freedom. Higher score means more freedom</li>
  <li><code class="language-plaintext highlighter-rouge">is_europe</code>: Whether or not a country is in Europe</li>
  <li><code class="language-plaintext highlighter-rouge">log_gdppc</code> - Log of GDP per capita</li>
</ul>

<p>We’ll answer the problem by fitting a linear model to the data and comparing the regression coefficients for countries inside and outside Europe. If the coefficients are significantly different, that will tell us about the effect of business freedom on GDP.</p>

<p>To supplement the model, we’ll also add an interaction term between <code class="language-plaintext highlighter-rouge">business_freedom</code> and <code class="language-plaintext highlighter-rouge">is_europe</code> and call it <code class="language-plaintext highlighter-rouge">business_freedom_x_region</code>. Here’s what the data looks like for countries inside and outside Europe.</p>

<p align="center">
  <img src="/assets/europe_data_viz.png" width="80%" height="80%" />
</p>

<p> </p>

<h2 id="regression-model">Regression Model</h2>

<p>Below is the regression model we have for our data that is based on observations $(X, y)$ and parameters $(\beta, \sigma)$.</p>

\[y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_3X_3 + \epsilon
\tag{1}\]

\[\beta = (\beta_0, \beta_1, \beta_2, \beta_3)
\notag\]

\[\epsilon \sim N(0, \sigma^{2})
\notag\]

<p> </p>

<h3 id="ordinary-linear-regression">Ordinary Linear Regression</h3>

<p>Ordinary linear regression takes equation <a href="#regression-model">(1)</a> and finds optimal values for $(\beta, \sigma)$ by minimizing the distance between the estimated value of $y$, and the observed value of $y$.
Below is an implementation of the model in Sklearn and a plot of the regression lines for European and non-European nations.</p>

<p> </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">features</span> <span class="o">=</span> <span class="p">[</span><span class="s">"business_freedom"</span><span class="p">,</span> <span class="s">"business_freedom_x_region"</span><span class="p">,</span> <span class="s">"is_europe"</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">features</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"log_gdppc"</span><span class="p">]</span>

<span class="n">reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">_</span> <span class="o">=</span> <span class="n">reg</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">coef</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">([</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="n">columns</span><span class="p">),</span> <span class="n">reg</span><span class="p">.</span><span class="n">coef_</span><span class="p">)])</span>
<span class="c1"># code for posterior plots is in the notebook linked at the bottom of this post
</span>
<span class="c1"># backout the slopes of the regression lines for nations in and out of Europe
</span><span class="k">print</span><span class="p">(</span><span class="s">"Slope for European Nations: "</span><span class="p">,</span>
      <span class="nb">round</span><span class="p">(</span><span class="n">coef</span><span class="p">[</span><span class="s">"business_freedom"</span><span class="p">]</span> <span class="o">+</span> <span class="n">coef</span><span class="p">[</span><span class="s">"business_freedom_x_region"</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Slope for non-European Nations: "</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">coef</span><span class="p">[</span><span class="s">"business_freedom"</span><span class="p">],</span> <span class="mi">3</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Slope for European Nations:  0.026
Slope for non-European Nations:  0.046
</code></pre></div></div>

<p align="center">
  <img src="/assets/linear_regression_fit.png" width="80%" height="80%" />
</p>

<p>Although the slope for non-European countries is twice as large as European countries (0.046 VS 0.026), the absolute value of both numbers is small. Are these estimates really that different? Ideally we want a measure of confidence for each estimate, then we can be more sure that they are different. Keep this problem in mind for the next section and we’ll see how Bayesian regression solves it.</p>

<p> </p>

<h3 id="bayesian-regression">Bayesian Regression</h3>

<p>Starting back from the regression model in <a href="#regression-model">(1)</a>, since $\epsilon$ is Normally distributed, $y$ is also Normally distributed in this model. So assuming that we have values for $(\beta, \sigma)$, we can write down a distribution for $y$. This is called the <em>likelihood</em> distribution.</p>

\[p(y | \beta, \sigma) \sim N (X\beta, \sigma^2)
\tag{2}\]

<p>Remember that we’re interested in estimating values for $\beta$ so that we can plug them back into our model and interpret the regression slopes. Before we get to estimating, the Bayesian framework allows us to add anything we know about our parameters to the model. In this case we don’t know anything about $\beta$ which is fine, but we know that $\sigma$ can’t be less than 0 because it is a standard deviation. This step is referred to as <em>prior specification</em>.</p>

<p>Since we don’t know anything about $\beta$, we’ll use an uninformative prior (think flat probability distribution) of $N(0, 5)$. For $\sigma$ we’ll use $U(0, 10)$, which ensures only positive values. The choice of $10$ as the upper bound here is somewhat arbitrary, the rational is that $\sigma$ probably won’t be very high based on the values of our response variable, $y$.</p>

\[p(\beta) \sim N(0, 5)
\notag\]

\[p(\sigma) \sim U(0, 10)
\notag\]

<p>Now we want to get the distribution $p(\beta | y, \sigma)$, which is proportional to the likelihood (2) multiplied by the priors. This is called the posterior formulation.
In real world applications, the posterior distribution is usually intractable (cannot be written down). Here’s where MCMC and variational inference come into play with Bayesian methods - they are used to draw samples from intractable posterior distributions, so that we can learn about our parameters. At this point you may be wondering why are we concerned with a distribution when $\beta$ is a number (vector of numbers). Well, the distribution gives us more information about $\beta$, then we can find point estimates by finding the mean, median, mode, etc.</p>

<p>To write the Bayesian model in Python, we’ll use <a href="http://pyro.ai">Pyro</a>. I skip over small details in the code, however Pyro has amazing examples in their docs if you want to learn more.</p>

<p> </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># specify the linear model
</span><span class="k">class</span> <span class="nc">BayesianRegression</span><span class="p">(</span><span class="n">PyroModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">PyroModule</span><span class="p">[</span><span class="n">nn</span><span class="p">.</span><span class="n">Linear</span><span class="p">](</span><span class="n">in_features</span><span class="p">,</span> <span class="n">out_features</span><span class="p">)</span>
        <span class="c1"># PyroSample used to declare priors:
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">.</span><span class="n">weight</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">).</span><span class="n">expand</span><span class="p">([</span><span class="n">out_features</span><span class="p">,</span> <span class="n">in_features</span><span class="p">]).</span><span class="n">to_event</span><span class="p">(</span><span class="mi">2</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">PyroSample</span><span class="p">(</span><span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">).</span><span class="n">expand</span><span class="p">([</span><span class="n">out_features</span><span class="p">]).</span><span class="n">to_event</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="n">sigma</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"sigma"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Uniform</span><span class="p">(</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">10.</span><span class="p">))</span>
        <span class="n">mean</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">).</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># sample from the posterior
</span>        <span class="n">obs</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="s">"obs"</span><span class="p">,</span> <span class="n">dist</span><span class="p">.</span><span class="n">Normal</span><span class="p">(</span><span class="n">mean</span><span class="p">,</span> <span class="n">sigma</span><span class="p">),</span> <span class="n">obs</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mean</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">BayesianRegression</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">auto_guide</span> <span class="o">=</span> <span class="n">AutoDiagonalNormal</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">svi</span> <span class="o">=</span> <span class="n">SVI</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span> <span class="c1"># bayesian regression class
</span>          <span class="n">guide</span> <span class="o">=</span> <span class="n">auto_guide</span><span class="p">,</span> <span class="c1"># using auto guide
</span>          <span class="n">optim</span> <span class="o">=</span> <span class="n">pyro</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="n">Adam</span><span class="p">({</span><span class="s">"lr"</span><span class="p">:</span> <span class="mf">0.05</span><span class="p">}),</span> <span class="c1"># optimizer
</span>          <span class="n">loss</span><span class="o">=</span><span class="n">Trace_ELBO</span><span class="p">())</span> <span class="c1"># loss function
</span>
<span class="n">num_iterations</span> <span class="o">=</span> <span class="mi">2500</span>
<span class="c1"># param_store is where pyro stores param estimates
</span><span class="n">pyro</span><span class="p">.</span><span class="n">clear_param_store</span><span class="p">()</span>
<span class="c1"># inference loop
</span><span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_iterations</span><span class="p">):</span>
    <span class="c1"># calculate the loss and take a gradient step
</span>    <span class="n">loss</span> <span class="o">=</span> <span class="n">svi</span><span class="p">.</span><span class="n">step</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="mi">250</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"[iteration %04d] loss: %.4f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)))</span>
</code></pre></div></div>

<p>For posterior inference, we use stochastic variational inference, which is a method used to approximate probability distributions. The code above initializes the stochastic variational inference sampler and runs it for $2500$ iterations. Now the <code class="language-plaintext highlighter-rouge">Predictive</code> class can be used to generate posterior samples for each parameter. We’ll only plot the posterior distributions for <code class="language-plaintext highlighter-rouge">business_freedom</code> and <code class="language-plaintext highlighter-rouge">business_freedom_x_region</code> as these are the most important.</p>

<p> </p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">num_samples</span> <span class="o">=</span> <span class="mi">1000</span>
<span class="n">predictive</span> <span class="o">=</span> <span class="n">Predictive</span><span class="p">(</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="p">,</span>
                        <span class="n">guide</span> <span class="o">=</span> <span class="n">auto_guide</span><span class="p">,</span>
                        <span class="n">num_samples</span> <span class="o">=</span> <span class="n">num_samples</span><span class="p">,</span>
                        <span class="n">return_sites</span><span class="o">=</span><span class="p">(</span><span class="s">"linear.weight"</span><span class="p">,</span> <span class="s">"linear.bias"</span><span class="p">,</span> <span class="s">"obs"</span><span class="p">,</span> <span class="s">"_RETURN"</span><span class="p">))</span>
<span class="n">pred</span> <span class="o">=</span> <span class="n">predictive</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="s">"linear.weight"</span><span class="p">]</span>
<span class="n">weight</span> <span class="o">=</span> <span class="n">weight</span><span class="p">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">weight</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">bias</span> <span class="o">=</span> <span class="n">pred</span><span class="p">[</span><span class="s">"linear.bias"</span><span class="p">]</span>
<span class="c1"># code for posterior plots is in the notebook linked at the bottom of this post
</span></code></pre></div></div>

<!-- space for plot of posterior disitbutrions -->
<p align="center">
  <img src="/assets/posteriors.png" width="85%" height="85%" />
</p>

<p> </p>

<p>Here is where the advantage of Bayesian linear regression starts to show. With Ordinary linear regression we end up with point estimates of parameters, but now we have an entire distribution for each parameter, and can use it to determine confidence levels. By combining appropriate posteriors and taking the mean, we can calculate a distribution for the slopes and compare them to the point estimates from <a href="#ordinary-linear-regression">ordinary linear regression</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">slope_inside_europe</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="c1"># business_freedom + business_freedom_x_region
</span><span class="n">slope_outside_europe</span> <span class="o">=</span> <span class="n">weight</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="c1"># business_freedom
</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Slope for European nations: "</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">slope_inside_europe</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># business_freedom + interaction
</span><span class="k">print</span><span class="p">(</span><span class="s">"Slope for non-European nations: "</span><span class="p">,</span> <span class="n">torch</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">slope_outside_europe</span><span class="p">).</span><span class="n">numpy</span><span class="p">())</span> <span class="c1"># business_freedom
</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">slope_inside_europe</span><span class="p">,</span> <span class="n">kde_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"European nations"</span><span class="p">})</span>
<span class="n">sns</span><span class="p">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">slope_outside_europe</span><span class="p">,</span> <span class="n">kde_kws</span><span class="o">=</span><span class="p">{</span><span class="s">"label"</span><span class="p">:</span> <span class="s">"Non-European nations"</span><span class="p">})</span>
<span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"log(GDP Per Capita) vs Business Freedom"</span><span class="p">);</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Slope for European nations:  0.023792317
Slope for non-European nations:  0.040710554
</code></pre></div></div>

<p> </p>

<p>These estimates are different to the ones from Ordinary linear regression. This is because of the priors we used in the Bayesian model. Neither method is necessarily “more correct”. Actually, if we were to specify all flat priors and sample from the true posterior distribution, the parameter estimates would be the same.</p>

<p align="center">
  <img src="/assets/bayesian_slopes.png" width="85%" height="85%" />
</p>
<!-- space for plot of difference in slopes -->

<p> </p>

<p>Although the absolute value of these slopes are small, we now have more confidence that the they are different becuase their distributions don’t overlap.</p>

<p>Returning to the questions we asked at the beginning of this post:</p>

<ul>
  <li><strong><em>Why should I even use this complicated black magic if other models are better?</em></strong> - Different tools for different jobs. Non-Bayesian models are not as expressive as their Bayesian counterparts. If all we care about is predictive power, then there’s little need for parameter confidence intervals and a non-Bayesian approach will suffice in most instances. However, when we want to do inference and compare effects (coefficients) with some level of confidence, Bayesian methods shine.</li>
  <li><strong><em>Since when is there a Bayesian version of simple linear regression?</em></strong> - There’s a Bayesian version of most models. If we have a model for data that can be expressed as a probability distribution, then we can specify distributions for its parameters and come up with a Bayesian formulation.</li>
  <li><strong><em>What in the world is <a href="https://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">MCMC</a> and should I even care?</em></strong> - MCMC is a family of methods used to sample arbitrary probability distributions. In Bayesian problems, the posterior distribution is not usually well defined, so we use MCMC algorithms to sample them.</li>
</ul>

<p> </p>

<p>All the code for this blog post can be viewed <a href="https://nbviewer.jupyter.org/github/jramkiss/jramkiss.github.io/blob/master/_posts/notebooks/regression_VS_bayesian_regression.ipynb">here</a>.</p>

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2020/03/01/regression-vs-bayesian-regression/</guid>
                <description>
                    
                    Walkthrough of the intuition behind Bayesian regression and a comparison with ordinary linear regression using a practical example in Pyro.
                    
                </description>
                <pubDate>Sun, 01 Mar 2020 02:54:00 -0500</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
        
            <item>
                <title>First Steps with Word Embeddings</title>
                <link>http://localhost:4000/2019/08/21/word-embeddings/</link>
                <content:encoded>
                    <![CDATA[
                    <p>Accurately representing words as vectors is a challenging, but necessary task in machine learning. Consider the following sentences:</p>

<ul>
  <li>The garden is pretty</li>
  <li>The garden is beautiful</li>
</ul>

<p>As humans we know that “pretty” and “beautiful” are similar, but how can we learn vector representations of these words so that they are “close” together? If this can be done, we can start to tackle bigger challenges, such as understanding customer reviews and summarizing content.</p>

<p>The goal of this post is to first explain the intuition behind these 3 methods for learning word embeddings (<a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">word2vec</a>, <a href="https://nlp.stanford.edu/pubs/glove.pdf">GloVe</a>, <a href="https://arxiv.org/pdf/1607.04606.pdf">fasttext</a>), then provide Python code to get started using them quickly.</p>

<h2 id="word2vec">Word2Vec</h2>

<p><a href="https://arxiv.org/pdf/1310.4546.pdf">Word2vec</a> really refers to two models for learning word vectors: the continuous bag-of-words (CBOW) and the skip-gram model. They are very similar - CBOW accepts context words as input and predicts a target word, whereas the skip-gram accepts a target word as input and predicts a context word.</p>

<p>Although we will primarily focus on the skip-gram, both models are single layer neural networks that accept one-hot encoded vectors as input. We learn the weights of the hidden layer, and each row of this weight matrix is a word vector. The algorithm forces word vectors closer to each other every time words appear in each other’s context, regardless of position in the context window. <strong>It does this by: (1) maximizing the probability that an observed word appears in the context of a target word and (2) minimizing the probability that a randomly selected word from the vocabulary appears in the context of the target word.</strong></p>

<p>If your understanding of neural network weights and the weight matricies is still shakey, <a href="http://neuralnetworksanddeeplearning.com/chap1.html">this chapter</a> gives a good into.</p>

<h3 id="deep-dive">Deep Dive</h3>

<p>The main idea behind the skip-gram model is that we take a word in an input sequence as the target word, and predict its context words. The context of a word is the $m$ words surrounding it. In figure 1, the window size is 2, the target word (“into”) is in red and its context words (“problems”, “turning”, “banking”, “crises”) are in blue.</p>

<p><br /></p>

<!--![](/assets/word2vec_viz.png)-->

<p align="center">
  <img src="/assets/word2vec_viz.png" width="90%" height="90%" />
</p>

<p>Figure 1: The skip gram prediction of target word “into” with window size 2. Taken from Stanford’s NLP course</p>

<p> </p>

<p>Let’s formalize some notation. We have an input sequence of words, $w_1, w_2,.., w_T$, each of which has a context window, $-m \le j \le m$. We’ll call this input sequence the <em>corpus</em>, and all its unique words the <em>vocabulary</em>. Each word in the vocabulary will have 2 vector representations during training, $u_o$ when it’s a context word and $v_c$ when it’s a target word.
In figure 1, $u_{turning}$ is the vector representation of “turning” as a context word, and $v_{banking}$ is the vector representation of “banking” as a target word.</p>

<p>We want to calculate the probability that each word in the window, $w_{t+j}$, appears in the context of the target word $w_t$. We’ll refer to this probability as $p(w_{t+j} \lvert w_t; \theta)$.
This may seem weird, but the probability is based on the vector representations of each word. When we encounter a word in the context of another, we alter their vector representations to be “closer”. So the more we see words in each other’s context, the closer their vectors are. The function $J(\theta)$ below describes this; $\theta$ is a placeholder representing all the vector representations. We minimize $-J(\theta)$ in order to find the optimal parameters that will maximize $p(w_{t+j} \lvert w_t; \theta)$.</p>

\[J(\theta) = -\frac{1}{T} \sum^{T}_{t = 1} \sum_{-m \le j \le m, j \ne 0} log(p(w_{t+j} \lvert w_t; \theta))\]

<p>The only problem here is we have no idea how to find $p(w_{t+j} \lvert w_t; \theta)$. We’ll start with using the softmax function. This essentially calculates how similar a context word, $u_o$, is to target word $v_c$, relative to all other context words in the vocabulary. The measure of similarity between two words is measured by the dot product $u_o^T v_c$, and a larger dot product means more similar words.</p>

\[p(w_{t+j} \lvert w_t; \theta) = \frac{e^{u_o^T v_c}}{\sum_{w=1}^W e^{u_w^T v_c}}\]

<p>Where:</p>

<ul>
  <li>$W$ is the size of the vocabulary</li>
  <li>$c$ and $o$ are indices of the words in the vocabulary at sequence positions $t$ and $j$ respectively</li>
  <li>$u_o = word2vec(w_{t+j})$</li>
  <li>$v_c = word2vec(w_t)$</li>
</ul>

<p>Although we now have a way of quantifying the probability a word appears in the context of another, the $\sum_{w=1}^W e^{u_w^T v_c}$ term requires us to iterate over all words in the vocabulary, making it computationally inefficient. To deal with this, we must approximate the softmax probability. One way of doing this is called negative sampling.</p>

<p> </p>

<h4 id="negative-sampling-loss"><strong>Negative Sampling Loss</strong></h4>

<p>Negative sampling overcomes the need to iterate over all words in the vocabulary to compute the softmax by sub-sampling the vocabulary. We sample $k$ words and determine the probability that these words <strong>do not</strong> co-occur with the target word. The intuition behind this is that a good model should be able to differentiate between data and noise.</p>

<p>To incorporate negative sampling, the objective function needs to be altered by replacing $p(w_{t+j} \lvert w_t)$ with:</p>

\[log(\sigma(u_o^T v_c)) + \sum_{i = 1}^{k}E_{j \sim P(w)} [log(\sigma(-u_j^T v_c))]\]

<p>Where $\sigma(.)$ is the <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a>.</p>

<p> </p>

<p>The new objective function becomes:</p>

\[J(\theta) = \frac{-1}{T} \sum_{t=1}^{T}J_t(\theta)
\notag\]

\[J_t(\theta) = log(\sigma(u_o^T v_c)) + \sum_{i = 1}^{k}E_{j \sim P(w)} [log(\sigma(-u_j^T v_c))]
\notag\]

\[P(w) = U(w)^{3/4}/Z
\notag\]

<p>Let’s look at each component of and try to convince ourselves this makes sense.</p>

<p><strong>The first part,</strong> $log(\sigma(u_o^Tv_c))$, can be interpreted as the log probability of the target and context words co-occurring. We want the model to find $u_o$ and $v_c$ to maximize this probability.</p>

<p><strong>The second part,</strong> $\sum_{i = 1}^{k}E_{j \sim P(w)} [log(\sigma(-u_j^T v_c))]$, is where the negative sampling happens. Let’s break this up more to make it clearer. It’ll come in handy to note that $\sigma(-x) = 1 - \sigma(x)$.</p>

<p>We can first drop the $E_{j \sim P(w)}$ term, since we already know we will be sampling words from some distribution, $P(w)$. We end up with:</p>

\[\sum_{i = 1}^{k} log(\sigma(-u_j^T v_c)) = \sum_{i = 1}^{k} log(1 - \sigma(u_j^T v_c))
\notag\]

<p>Now that this is easier to read, we’re taking the log of 1 minus the probability that the sampled word, $j$, appears in the context of the target word $c$. This is just log probability that $j$ does <strong>not</strong> appear in the context of the $c$. Since $j$ is randomly drawn out of ~$10^6$ words, there’s a very small chance it appears in the context of $c$, so this probability should be high. We do this for each of the $k$ sampled words.</p>

<p>Finally, we have to specify a distribution for negative sampling, $P(w) = U(w)^{3/4}/Z$. Here, $U(w)$ is the count of each word in the corpus (unigram distribution) and is raised to the $\frac{3}{4}$th power to sample rarer words in the vocabulary. $Z$ is just a normalization term to turn $P(w)$ into a probability distribution.</p>

<p>To summarize, this loss function is trying to maximize the probability that word $o$ appears in the context of word $c$, while minimizing the probability that a randomly selected word from the vocabulary does not appear in the context of word $c$. We use the gradient of this loss function to iteratively update the word vectors, $u_o$ and $v_c$, and eventually get our word embeddings.</p>

<p><a href="http://mccormickml.com/2016/04/19/word2vec-tutorial-the-skip-gram-model/">Here</a> is a <em>great</em> tutorial on the skip-gram model!</p>

<p> </p>

<hr />

<h2 id="glove">GloVe</h2>

<p>GloVe (Global Vectors) is another architecture for learning word embeddings that improves on the skip-gram model by incorporating corpus statistics. Since the skip-gram model looks at each window independently, it loses corpus statistics. In contrast, GloVe uses word co-occurrence counts to capture global information about the corpus. <strong>GloVe learns word embeddings by minimizing the difference between word vector dot products and their log co-occurrence counts.</strong></p>

<h3 id="deep-dive-1">Deep Dive</h3>

<h4 id="the-co-occurrence-matrix"><strong>The Co-Occurrence Matrix</strong></h4>

<p>The co-occurrence matrix, $X$, is generated from the corpus and vocabulary. The entry at $X_{ij}$ is then the number of times word $j$ occurs in the context of word $i$. Context is defined in the same way as the skip-gram model. Summing over all the values in row $i$, will give the number of words that occur in its context, $X_i = \sum_k X_{ik}$. Then the probability of word $j$ occurring in the context of word $i$ is $P(i \lvert j) = \frac{X_{ij}}{X_i}$.</p>

<p>Below is the co-occurrence matrix for the corpus containing:</p>

<ul>
  <li>“I like deep learning.”</li>
  <li>“I like NLP.”</li>
  <li>“I enjoy flying.”</li>
</ul>

<p align="center">
  <img src="/assets/cooccurrence_matrix.png" width="80%" height="80%" />
</p>

<p> </p>

<h4 id="from-softmax-to-glove"><strong>From Softmax to GloVe</strong></h4>

<p>We can find global loss using the softmax function, $Q_{ij}$, by summing over all target-context word pairs.</p>

\[J = - \sum_{i \in corpus} \sum_{j \in context} log (Q_{ij})
\notag\]

<p>Since words $i$ and $j$ appear $X_{ij}$ times in the corpus, we don’t need to iterate over all windows in the corpus, but can iterate over the vocabulary and multiply by the co-occurrence count.</p>

\[J = - \sum_{i = 1}^{W} \sum_{j = 1}^{W} X_{ij} log Q_{ij}
\notag\]

<p>Re-arranging some terms, we can come up with this:</p>

\[J = - \sum_{i = 1}^{W} X_{i} \sum_{j = 1}^{W} P_{ij}log(Q_{ij})
\notag\]

<p> </p>

<p><strong>What’s going on here?</strong></p>

<ul>
  <li><strong>Where did $P_{ij}$ come from?</strong> - Remember that $P_{ij} = \frac{X_{ij}}{X_i}$ and $X_i = \sum_k X_{ik}$, therefore we can substitute $X_{ij} = P_{ij}X_i$.</li>
  <li><strong>What’s the relationship between $P_{ij}$ and $Q_{ij}$?</strong> - $P_{ij}$ is the probability that word $j$ appears in the context of word $i$, but $Q_{ij}$ is also the probability that word $j$ appears in the context of word $i$. The difference between the two lies in how they are calculated. $P_{ij}$ is calculated using the co-occurrence matrix and doesn’t change. $Q_{ij}$ is the naive softmax probability, that is calculated using the dot product of word vectors $u_j$ and $v_i$. We have the ability to change $Q_{ij}$ by changing these vectors.</li>
  <li><strong>What’s the point of $P_{ij}log(Q_{ij})$?</strong> - Now that we’ve refreshed our memory of $P$ and $Q$, we can see that $P$ is the <em>true</em> probability distribution of context and target words, and $Q$ is some made up distribution based on the “goodness” of the word vectors. We really want these two distributions to be close to each other. Observing $H = P_{ij}log(Q_{ij})$, when $P$ and $Q$ are close to each other, $H$ is small, and when $P$ and $Q$ are far apart, $H$ is larger. Our end goal is the minimization of $J$, so the smaller $H$ is the better. This term is the cross-entropy between distributions $P$ and $Q$.</li>
</ul>

<p>The problem here is that cross-entropy requires normalized versions of $Q_{ij}$ and $P_{ij}$ which we have to iterate over the entire vocabulary to calculate. This is the reason for using Negative Sampling in the skip-gram model. GloVe’s approach to this is dropping the normalization terms completely, so we end up with $\hat{P}$ and $\hat{Q}$, which are unnormalized distributions. The cross-entropy function is now useless, so we change our objective function to be a squared error function.</p>

\[\hat{J} = \sum_{i = 1}^{W} X_{i} \sum_{j = 1}^{W} (\hat{P}_{ij} - \hat{Q}_{ij})^2
\notag\]

<p>Now we have the squared error, weighted by the number of co-occurrences of words $i$ and $j$. There’s one last problem with this, which is that some co-occurrence counts can be massive. This will affect both the weights, $X_i$, and $\hat{P_{ij}} = X_{ij}$. To deal with this explosion in the squared term, we take $log(hat{P})$ and $log(hat{Q})$) and to deal with the explosion of weights, we introduce a function, $f$ that caps the co-occurrence count weight. We’ll apply $f$ to each target-context pair, $X_{ij}$ as opposed to only $X_i$. The new loss function becomes:</p>

\[\hat{J} = \sum_{w = 1}^{W} \sum_{w = 1}^{W} f(X_{ij}) (u_j^T v_i - log(X_{ij}))^2
\notag\]

<p>This is the loss function that the GloVe model minimizes.</p>

<hr />

<h2 id="fasttext">Fasttext</h2>

<p><a href="https://github.com/facebookresearch/fastText">Fasttext</a> is a powerful library for learning word embeddings that was introduced by Facebook in 2016. Its roots come from the <a href="#deep-dive">word2vec</a> models.</p>

<p>Word2vec trains a unique vector for each word, ignoring important word sub-structure (morphological structure) and making out-of-vocabulary prediction impossible. Fasttext attempts to solve this by treating each word as a sum of its subwords. These subwords can be defined in any way, however the simplest form is a character n-gram. A vector representation is associated with each n-gram, then the vector for each word is simply the sum of each of its n-grams. <strong>Fasttext learns word embeddings for each subword, then treats each word as a sum of its subwords.</strong></p>

<h3 id="deep-dive-2">Deep Dive</h3>

<p>Before starting, we’ll take a step back to quantifying how similar two word vectors are. Both GloVe and word2vec do this using dot products, however we can think of the similarity more generally as an arbitrary function, $s(u_j, v_c)$.</p>

<p>Fasttext redefines this similarity measure, and represents words as a sum of smaller words, each of length $n$, called n-grams. To help the model learn prefixes and suffixes, we append “&lt;” to the front and “&gt;” to the back of each word. Then for n=3, the n-grams of “where” are:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;where&gt; = [&lt;wh, whe, her, ere, re&gt;]
</code></pre></div></div>

<p>We have no way of determining the difference between the subword “her” and the full-word “her” (there definitely should be a difference). Appending the special characters around each word helps with this, as the tri-gram “her” is now different from the sequence “&lt;her&gt;”.</p>

<p>More formally, suppose we have all n-grams in the vocabulary, $G$, each represented by a vector, $\boldsymbol{z}_g$. We can refer to all the n-grams of some word, $w$, by $G_w$. Then $w$ can be represented as a sum of all n-grams. The new similarity function becomes:</p>

\[s(w, c) = \sum_{g \in G_w} \boldsymbol{z}_g^T v_c
\notag\]

<p>We learn the embeddings of each character n-gram and then each word embedding is a sum of its n-gram vectors.</p>

<hr />

<h2 id="word-embeddings-in-python">Word Embeddings in Python</h2>

<p>Now let’s explore word embeddings using pre-trained models in the <code class="language-plaintext highlighter-rouge">gensim</code> Python package. If you don’t have it installed, run <code class="language-plaintext highlighter-rouge">pip install gensim</code> in your command line. Gensim offers pre-trained models from their <code class="language-plaintext highlighter-rouge">gensim.downloader</code> method and each model used here embeds words in a 300-dimensional space. A full list of the models available can be found <a href="https://github.com/RaRe-Technologies/gensim-data">here</a>, or by running <code class="language-plaintext highlighter-rouge">python -m gensim.downloader --info</code> in your command line.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">gensim</span>
<span class="kn">import</span> <span class="nn">gensim.downloader</span> <span class="k">as</span> <span class="n">api</span>

<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># clearer images if you're using a Jupyter notebook
</span><span class="o">%</span><span class="n">config</span> <span class="n">InlineBackend</span><span class="p">.</span><span class="n">figure_format</span><span class="o">=</span><span class="s">'retina'</span>
</code></pre></div></div>

<h3 id="word2vec-1">Word2vec</h3>

<p>For word2vec, we’ll use Google’s News dataset model, trained on news articles with a vocabulary of 3 million words and 300 dimensional embedding vectors. <a href="https://github.com/chrisjmccormick/inspect_word2vec">This repo</a> has an in-depth analysis of the words in the model.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">word2vec_model_path</span> <span class="o">=</span> <span class="s">"word2vec-google-news-300"</span>
<span class="k">print</span><span class="p">(</span><span class="n">api</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="n">word2vec_model_path</span><span class="p">))</span>

<span class="n">word2vec_model</span> <span class="o">=</span> <span class="n">api</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">word2vec_model_path</span><span class="p">)</span>
<span class="n">w2v</span> <span class="o">=</span> <span class="n">word2vec_model</span><span class="p">.</span><span class="n">wv</span>

<span class="c1"># remove from env
</span><span class="k">del</span> <span class="n">word2vec_model</span>
</code></pre></div></div>

<h3 id="glove-1">GloVe</h3>

<p>The glove-wiki-gigaword-300 model used here is trained on 6B tokens from Wikipedia 2014 and the Gigaword dataset, other pre-trained GloVe models can be downloaded <a href="https://nlp.stanford.edu/projects/glove/">from Stanford</a> or <a href="https://github.com/RaRe-Technologies/gensim-data/releases/download/glove-wiki-gigaword-100">from Gensim</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">glove_model_path</span> <span class="o">=</span> <span class="s">"glove-wiki-gigaword-300"</span>
<span class="k">print</span><span class="p">(</span><span class="n">api</span><span class="p">.</span><span class="n">info</span><span class="p">(</span><span class="n">glove_model_path</span><span class="p">))</span>

<span class="n">glove_model</span> <span class="o">=</span> <span class="n">api</span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="n">glove_model_path</span><span class="p">)</span>
<span class="n">glove</span> <span class="o">=</span> <span class="n">glove_model</span><span class="p">.</span><span class="n">wv</span>

<span class="k">del</span> <span class="n">glove_model</span>
</code></pre></div></div>

<h3 id="fasttext-1">Fasttext</h3>

<p>Fasttext provides pre-trained models on for multiple languages, which can be used in different ways (through the command line, downloading the model, through <code class="language-plaintext highlighter-rouge">gensim</code>, etc.). We’ll use the English model provided by <code class="language-plaintext highlighter-rouge">Gensim</code> which is trained on Wikipedia 2017 and news data, but you can go through <a href="https://github.com/facebookresearch/fastText/blob/master/docs/pretrained-vectors.md">their Github</a> to see more.</p>

<h4 id="word-comparison"><strong>Word Comparison</strong></h4>

<p>Now we have vector representations for all words in the vocabulary in <code class="language-plaintext highlighter-rouge">wv</code> and can compare the different models. We’ll add and subtract some word vectors, then see what the closest word to the resulting vector is. Papers and blog posts have exhausted the “king” - “man” + “woman” = “queen” example, so I’ll present some new ones.</p>

<p>Results generated by the <code class="language-plaintext highlighter-rouge">find_most_similar</code> function are of the form (word, cosine similarity), where each word is the closest to the one parsed into the function. Cosine similarity values closer to 1 mean that the vectors (words) are more similar. The function definition can be found in the <a href="#appendix">Appendix</a>.</p>

<p>Start with: <code class="language-plaintext highlighter-rouge">doctor - man + woman</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span> <span class="p">(</span><span class="s">"word2vec: Doctor - Man + Woman"</span><span class="p">)</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="n">w2v</span><span class="p">[</span><span class="s">"doctor"</span><span class="p">]</span> <span class="o">-</span> <span class="n">w2v</span><span class="p">[</span><span class="s">"man"</span><span class="p">]</span> <span class="o">+</span> <span class="n">w2v</span><span class="p">[</span><span class="s">"woman"</span><span class="p">],</span> <span class="n">w2v</span><span class="p">,</span>
                  <span class="p">[</span><span class="s">"man"</span><span class="p">,</span> <span class="s">"doctor"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">])</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"GloVe: Doctor - Man + Woman"</span><span class="p">)</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="n">glove</span><span class="p">[</span><span class="s">"doctor"</span><span class="p">]</span> <span class="o">-</span> <span class="n">glove</span><span class="p">[</span><span class="s">"man"</span><span class="p">]</span> <span class="o">+</span> <span class="n">glove</span><span class="p">[</span><span class="s">"woman"</span><span class="p">],</span> <span class="n">glove</span><span class="p">,</span>
                  <span class="p">[</span><span class="s">"man"</span><span class="p">,</span> <span class="s">"doctor"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">])</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"fasttext: Doctor - Man + Woman"</span><span class="p">)</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="n">fasttext</span><span class="p">[</span><span class="s">"doctor"</span><span class="p">]</span> <span class="o">-</span> <span class="n">fasttext</span><span class="p">[</span><span class="s">"man"</span><span class="p">]</span> <span class="o">+</span> <span class="n">fasttext</span><span class="p">[</span><span class="s">"woman"</span><span class="p">],</span> <span class="n">fasttext</span><span class="p">,</span>
                  <span class="p">[</span><span class="s">"man"</span><span class="p">,</span> <span class="s">"doctor"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> word2vec: Doctor - Man + Woman
 [('gynecologist', 0.7276507616043091),
  ('nurse', 0.6698512434959412),
  ('physician', 0.6674120426177979)]

 GloVe: Doctor - Man + Woman
 [('physician', 0.6203880906105042),
  ('nurse', 0.6161285638809204),
  ('doctors', 0.6017279624938965)]

 fasttext: Doctor - Man + Woman
 [('gynecologist', 0.6874127388000488),
  ('nurse-midwife', 0.6773605346679688),
  ('physician', 0.6561880111694336)]
</code></pre></div></div>

<p>Interesting, what about if we make a subtle change to <code class="language-plaintext highlighter-rouge">doctor - woman + man</code>?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span> <span class="p">(</span><span class="s">"word2vec: Doctor - Woman + Man"</span><span class="p">)</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="n">w2v</span><span class="p">[</span><span class="s">"doctor"</span><span class="p">]</span> <span class="o">-</span> <span class="n">w2v</span><span class="p">[</span><span class="s">"woman"</span><span class="p">]</span> <span class="o">+</span> <span class="n">w2v</span><span class="p">[</span><span class="s">"man"</span><span class="p">],</span> <span class="n">w2v</span><span class="p">,</span>
                  <span class="p">[</span><span class="s">"man"</span><span class="p">,</span> <span class="s">"doctors"</span><span class="p">,</span> <span class="s">"doctor"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">])</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"GloVe: Doctor - Woman + Man"</span><span class="p">)</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="n">glove</span><span class="p">[</span><span class="s">"doctor"</span><span class="p">]</span> <span class="o">-</span> <span class="n">glove</span><span class="p">[</span><span class="s">"woman"</span><span class="p">]</span> <span class="o">+</span> <span class="n">glove</span><span class="p">[</span><span class="s">"man"</span><span class="p">],</span> <span class="n">glove</span><span class="p">,</span>
                  <span class="p">[</span><span class="s">"man"</span><span class="p">,</span> <span class="s">"doctors"</span><span class="p">,</span> <span class="s">"doctor"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">,</span> <span class="s">"dr."</span><span class="p">])</span>

<span class="k">print</span> <span class="p">(</span><span class="s">"fasttext: Doctor - Woman + Man"</span><span class="p">)</span>
<span class="n">find_most_similar</span><span class="p">(</span><span class="n">fasttext</span><span class="p">[</span><span class="s">"doctor"</span><span class="p">]</span> <span class="o">-</span> <span class="n">fasttext</span><span class="p">[</span><span class="s">"woman"</span><span class="p">]</span> <span class="o">+</span> <span class="n">fasttext</span><span class="p">[</span><span class="s">"man"</span><span class="p">],</span> <span class="n">fasttext</span><span class="p">,</span>
                  <span class="p">[</span><span class="s">"man"</span><span class="p">,</span> <span class="s">"doctors"</span><span class="p">,</span> <span class="s">"doctor"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">,</span> <span class="s">"dr."</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>word2vec: Doctor - Woman + Man
[('physician', 0.6823904514312744),
 ('surgeon', 0.5908077359199524),
 ('dentist', 0.570309042930603)]

GloVe: Doctor - Woman + Man
[('physician', 0.5128607153892517),
 ('he', 0.4661550223827362),
 ('brother', 0.46356332302093506)]

fasttext: Doctor - Woman + Man
[('physician', 0.6969557404518127),
 ('docter', 0.6826808452606201),
 ('non-doctor', 0.6698156595230103)]
</code></pre></div></div>

<p>This is a different result from the original results. Biases in the training data are expressed by the model. Also interestingly, there are some misspelled words in fasttext. This is because of the difference in learning methods.</p>

<p> </p>

<h4 id="visualizing-embeddings"><strong>Visualizing Embeddings</strong></h4>

<p>For the sake of completeness, I plotted words from different walks of life to see if the algorithms were able to unravel their semantic similarities/differences. The first 2 principal components of each word vector are plotted. Some expected similarities are seen here, however, we lose a lot of information from reducing the dimension from 300 to 2.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plot_embeds</span><span class="p">([</span><span class="s">"dog"</span><span class="p">,</span> <span class="s">"cat"</span><span class="p">,</span> <span class="s">"hamster"</span><span class="p">,</span> <span class="s">"pet"</span><span class="p">]</span> <span class="o">+</span>                   <span class="c1"># animals
</span>            <span class="p">[</span><span class="s">"boy"</span><span class="p">,</span> <span class="s">"girl"</span><span class="p">,</span> <span class="s">"man"</span><span class="p">,</span> <span class="s">"woman"</span><span class="p">]</span> <span class="o">+</span>                    <span class="c1"># humans
</span>            <span class="p">[</span><span class="s">"grown"</span><span class="p">,</span> <span class="s">"adult"</span><span class="p">,</span> <span class="s">"young"</span><span class="p">,</span> <span class="s">"baby"</span><span class="p">]</span> <span class="o">+</span>                <span class="c1"># age
</span>            <span class="p">[</span><span class="s">"german"</span><span class="p">,</span> <span class="s">"english"</span><span class="p">,</span> <span class="s">"spanish"</span><span class="p">,</span> <span class="s">"french"</span><span class="p">]</span> <span class="o">+</span>         <span class="c1"># languages
</span>            <span class="p">[</span><span class="s">"mathematics"</span><span class="p">,</span> <span class="s">"physics"</span><span class="p">,</span> <span class="s">"biology"</span><span class="p">,</span> <span class="s">"chemistry"</span><span class="p">],</span>  <span class="c1"># natural sciences
</span>            <span class="n">w2v</span><span class="p">,</span>
            <span class="n">title</span> <span class="o">=</span> <span class="s">"word2vec Embedding"</span><span class="p">)</span>
<span class="c1"># run this again, but changing w2v to glove and fasttext
</span></code></pre></div></div>
<!--
![](/assets/word2vec_embedding.png)
![](/assets/glove_embedding.png)
![](/assets/fasttext_embedding.png)
-->

<p align="center">
  <img src="/assets/word2vec_embedding.png" width="80%" height="80%" />
</p>

<p align="center">
  <img src="/assets/glove_embedding.png" width="80%" height="80%" />
</p>

<p align="center">
  <img src="/assets/fasttext_embedding.png" width="80%" height="80%" />
</p>

<p>Wrapping up, there are some key differences between word2vec (skip-gram), GloVe and fasttext. The skip-gram iterates over the corpus predicting context words given a target word. GloVe builds on this by incorporating global corpus statistics using word co-occurrences. The results are similar to word2vec. Fasttext also builds on word2vec by breaking each word into a sum of its sub-words. It learns vectors for each subword, then combines them for prediction. This allows out-of-vocabulary prediction, but introduces the risk of misspelled words.</p>

<p>Both word2vec and GloVe can be used as frameworks for learning general similarities in text without considering what each token is made of. This makes them useful for tasks like finding similar movies given a sequence of movies watched by users. Fasttext on the other hand is more robust for translation tasks, where the likelihood of encountering an out-of-vocabulary word is higher.</p>

<hr />

<h2 id="more-code">More Code</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># find the 3 most similar words to the vector "vec"
</span><span class="k">def</span> <span class="nf">plot_embeds</span><span class="p">(</span><span class="n">word_list</span><span class="p">,</span> <span class="n">wv</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">word_embeddings</span> <span class="o">=</span> <span class="bp">None</span><span class="p">,</span> <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span> <span class="p">:</span>
    <span class="c1"># pca on the embedding
</span>    <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">pca</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">wv</span><span class="p">[</span><span class="n">word_list</span><span class="p">])</span>

    <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">figsize</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
    <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">label</span><span class="p">,</span> <span class="n">point</span> <span class="ow">in</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">word_list</span><span class="p">,</span> <span class="n">X</span><span class="p">)):</span>
        <span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">annotate</span><span class="p">(</span><span class="n">label</span><span class="p">,</span> <span class="p">(</span><span class="n">point</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mf">0.075</span><span class="p">,</span> <span class="n">point</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mf">0.075</span><span class="p">))</span>
    <span class="c1"># Turn off tick labels
</span>    <span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">xticks</span><span class="p">([])</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">yticks</span><span class="p">([])</span>

<span class="k">def</span> <span class="nf">find_most_similar</span> <span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">wv</span><span class="p">,</span> <span class="n">words</span> <span class="o">=</span> <span class="bp">None</span><span class="p">)</span> <span class="p">:</span>
    <span class="c1"># vec: resulting vector from word Arithmetic
</span>    <span class="c1"># words: list of words that comprise vec
</span>    <span class="n">s</span> <span class="o">=</span> <span class="n">wv</span><span class="p">.</span><span class="n">similar_by_vector</span><span class="p">(</span><span class="n">vec</span><span class="p">,</span> <span class="n">topn</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    <span class="c1"># filter out words like "king" and "man", or else they will be included in the similarity
</span>    <span class="k">if</span> <span class="p">(</span><span class="n">words</span> <span class="o">!=</span> <span class="bp">None</span><span class="p">)</span> <span class="p">:</span>
        <span class="n">word_sim</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">words</span><span class="p">),</span> <span class="n">s</span><span class="p">))[:</span><span class="mi">3</span><span class="p">]</span>
    <span class="k">else</span> <span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">s</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">word_sim</span><span class="p">)</span>
</code></pre></div></div>

<hr />

                    ]]>
                </content:encoded>
                <guid isPermaLink="false">/2019/08/21/word-embeddings/</guid>
                <description>
                    
                    This post explains word2vec, GloVe and fasttext in detail and shows how to use pre-trained models for each in Python.
                    
                </description>
                <pubDate>Wed, 21 Aug 2019 19:22:00 -0400</pubDate>
                <author>Jonathan Ramkissoon</author>
            </item>
        
    
  </channel>
</rss>
