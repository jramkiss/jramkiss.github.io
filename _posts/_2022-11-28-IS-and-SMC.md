---
layout: post
title: "From Importance Sampling to Particle Filtering"
date: 2022-11-28 2:22
comments: true
author: "Jonathan Ramkissoon"
math: true
summary: Using importance sampling for the Bayesian filtering problem
---


## Gaussian Copula Resampling

It's a bit difficult to follow the point here.  In my opinion, the point is that the Gaussian Copula is essentially always going to fit the filtered distribution better than an MVN, because the GC can estimate the marginal distributions consistently.

So perhaps you could structure things as follows:

- Definition of a copula (essentially as you have done in 1-3).

- Now suppose you have a distribution H that you wish to model with a given copula C.  The copula estimator is then H_hat(x) = C(H_1(x_1), ..., H_d(x_d)).  Note that H_hat has exactly the same marginal distributions as H.

- A particularly simple yet flexible copula is the Gaussian copula (2.3).  For continuous random variables \XX, the Gaussian copula can be sampled from using the reparametrization trick as follows:

[generate multivariate normal, transform each coordinate using X_i = H_i^{-1}(pnorm(Z_i)).]

Our proposal is to use the Gaussian copula as a differentiable particle resampler.  It is typically a bettter approximation than the MVN, since it not only captures dependence structure but also gets the marginals right.  

Now you can discuss fitting and resampling.  It's OK to pretty much just say the exact steps are presented in Algorithm 2.  The one thing to draw attention to is that we need a continuous estimator of each inverse-cdf H_i^{-1}.  This is obtained by inverting a linearly interpolated CDF approximation H_hat_i(X_i) as described in [14].

---

The main contribution of this work is a continuous and differentiable resampling method based on copulas. Copulas reduce the bias imposed by approximating the filtering distribtuion with a multivariate Gaussian as the margins are estimated consistently. Given their importance to this work, we provide background into copula functions and then present the Gaussian copula used here, the Gaussian copula, is presented.

\subsection{Copulas and Dependence}

A copula is a cumulative distribution function with uniform marginals that describes dependence. The key idea, based on Sklar's theorem, is that any joint distribution can be expressed as its marginal distributions and a function that describes their dependence, called the copula function. More formally, a copula, \(C: [0,1]^d \to [0,1]\) is a function with the following properties:

\begin{enumerate}
    \item \(C(u_1, \dots, u_d)\) is non-decreasing for each component, $u_i$
    \item The $i^{th}$ marginal distribution is obtained by setting \(u_j = 1, j \ne i\) as:

\begin{equation}
    u_i = C(1, \dots, 1, u_i, 1, \dots, 1)
\end{equation}

    \item C is $d$-increasing. i.e. for any box $[a, b] \subset [0, 1]^d$ with non-empty volume, \(C([a, b]) > 0\)
\end{enumerate}

\textbf{todo: Don't really understand Martin's comment here, but I changed $X$ to $\XX$ in some places...}

To make the connection between these functional properties and CDF's, recall that for a CDF, $F(\XX)$, we have $F(\XX) \sim U(0, 1)$. Then in the multivariate case, \(\XX \in \mathcal{R}^d\) with distribution function $H(\XX) = p(\XX_1 \le x_1, \dots, \XX_d \le x_d)$ and marginals $H_1, \dots, H_d$, the joint distribution \((H_1(x_1), \dots, H_d(x_d))\) is a copula, $C_X$ defined as:

\begin{align*}
    C_X(u_1, \dots, u_d) &= p(H_1(\XX_1) \le u_1, \dots, H_d(\XX_d) \le u_d) \\
                         &= p(\XX_1 \le H_1^{-1}(u_1), \dots, \XX_d \le H_d^{-1}(u_d)) \\
                         &= H(H_1^{-1}(u_1), \dots, H_d^{-1}(u_d))
\end{align*}

Now suppose we have a distribution $H$ that we wish to model with a copula, $C$. The copula estimate of $H$ is given by $\hat{H}(\XX) = C(H_1(\XX_1), \dots, H_d(\XX_d))$. Notice that $\hat{H}$ has the exact marginals as $H$. For a more thorough discussion about copulas, see \cite{Haugh2016}, \cite{nelson2006}.

Our proposal is to use the Gaussian copula as a differentiable particle resampler. It is typically a bettter approximation than the MVN, since it not only captures dependence structure but also gets the marginals right.

<!-- 
This is presented in Sklar's theorem, which states that there exists a copula $C$ such that:

\begin{equation}
    H(x_1, \dots, x_d) = C(H_1(x_1), \dots, H_d(x_d))
\end{equation}

and if $X$ is continuous, this copula is unique. For a more thorough discussion about copulas, see \cite{Haugh2016}, \cite{nelson2006}. -->

\subsection{Fitting Gaussian Copulas}

A particularly simple, yet flexible copula is the Gaussian  copula. In this paper we use a Gaussian copula to estimate the filtering distribution at timestep, $t$. For a given correlation matrix, $\rho \in \mathcal{R}^{(d, d)}$, the Gaussian copula can be written as:

\begin{equation}
    C_{\rho}(u_1, \dots, u_d) = \Phi_{\rho}(\phi^{-1}(u_1), \dots, \phi^{-1}(u_d))
\end{equation}

Where $\phi^{-1}(u)$ is the CDF of a standard normal and \(\Phi_{\rho}\) is the CDF of a multivariate Normal with covariance matrix $\rho$. The estimation of $\rho$ involves finding a weighted correlation of empirical quantiles for each particle. Specifically, given particles, $\{\XX_t^i\} \in \mathcal{R}^d, i=1, \dots, N$ and normalized weights, $\tilde{w}_t^i, i = 1, \dots, N$, we find the weighted correlation of $\hat{F}_j(\XX_{tj}^i), i = 1, \dots, N, j = 1, \dots, d$. Where $\hat{F}_j(\XX)$ is the empirical CDF for marginal $j$.  Note that a continuous estimator of $\hat{F}_j(\XX)$ is needed to ensure that the resulting log-likelihood estimate is continuous w.r.t. parameters. To ensure this, we employ the method presented in \cite{Malik2011} used for a continuous-estimate of one-dimensional filtering distributions. 

Fitting the Gaussian copula to the filtering distribution utilizes the continuous approximation of the CDF presented in \cite{Malik2011}. The resampling step is then done using the reparameterization trick, which is described in algorithm \ref{alg:gausscop}.

\begin{algorithm}
\caption{Re-sampling using a Gaussian Copula}
\label{alg:gausscop}
\textbf{Input:} Particles and normalized weights, $(\XX^i, \tilde{w}^i), i = 1, \dots, N$, with $\XX^i \in \mathcal{R}^d$
\begin{algorithmic}
\ForEach{$i = 1, \dots N$ and $j = 1, \dots d$}
\State $Y[i, j] = \hat{F}_j(\XX_{j}^i)$
\EndFor
\State Let $\hat{\rho}$ be the weighted correlation of $Y$ with Cholesky decomposition $A$, such that $\hat{\rho} = AA^T$
\State Generate $Z \sim MVN(0, I_d)$
\State Let $U = \phi(AZ)$
\State Apply the inverse of the continuous approximation of the CDF from \cite{Malik2011}: $\hat{F}^{-1}_j(u_i)$
\end{algorithmic}
\end{algorithm}


---

## State-Space Models

State-space models (also called hidden Markov-models) are a general class of latent-variable models, characterized by an unobserved discrete-time Markov process, ${X}_{t \ge 0}$, and observations, ${Y_t }_{t\ge 0}$. In these models, $Y_t$ is conditionally independent given $X_t$. 

A state-space model is fully specified by the following two distributions, namely the transition density and measurement model respectively. Both of which are parameterized by static parameters, $\theta$:

$$
X_t \mid X_{t-1} \sim f(X \mid X_{t-1}, \theta), \\
Y_t \mid Y_t \sim g(Y \mid X_t, \theta)
$$


<div class='figure' align="center">
    <img src="/assets/SSM.png" width="90%">
    <div class='caption' width="40%" height="40%">
        <p> Graphical representation of a state-space model  </p>
    </div>
</div>

We are generally interested in the estimation of the latent process, $\{X_t\}_{t \ge 0}$, or the static parameters, $\theta$, or both, conditional on the observed data, $Y_{1:t}$. The former is the estimation of $p(X_t \mid Y_{1:t}), 1 \le t \le T$, which is the Bayesian filtering problem. The latter is the estimation of the posterior $p(\theta \mid Y_{1:T}, X_{0:T})$, which is the standard parameter inference problem.

The challenge posed by the filtering problem is in the efficient estimation of the filtering distribution, $p(X_t \mid Y_{1:t})$. As we will see in the next sections, importance sampling provides a way of estimating an arbitrary distribution, $p(X)$ using weighted samples from a proposal, but naively applying this to filtering problem is inefficeint.

The parameter inference problem is challenging because for non-linear, non-Gaussian state-space models the likelihood function is intractable. Calculating this likelihood involves integrating out all the latent states, $X_t$, as follows: 

$$
L(\theta \mid Y_{0:T}) = \int \left[\pi(X_0) \cdot \prod_{n=0}^T g(Y_n \mid X_n, \theta) \cdot \prod_{n=1}^T f(X_n \mid X_{n-1}, \theta)\right] d X_{0:T}.
$$

Where $\pi(X_0)$ is a prior on the initial state of the latent process. Again, importance sampling provides a way of approximating integrals, but will be grossly inefficient for something as complex and high-dimensional as this.


## Approximating Distrbituions with Importance Sampling 

Importance sampling gives us a way of approximating integrals, however in the filtering problem we are interested in estimating a distribution. We can use the fact that any distribution, $\pi(x)$, can be expressed as a sum of Dirac delta functions. Suppose $\{X^{(i)}\}_{i=1}^N$ are samples from $\pi(x)$, then the empirical representation of $\pi(x)$ is:

$$
\hat{\pi}^N(dx) = \frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx)
$$

Where $\delta_{X}(A)$ is the Dirac measure, defined as: 


$$
\delta_{X}(A) =
\begin{cases}
1 \qquad X \in A,\\
0 \qquad X \notin A
\end{cases}
$$

As an aside, I'll quickly review how this empirical representation can be used in the importance sampling context, presented in [this post](/_posts/2022-10-22-importance-sampling.md).

Suppose we want to approximate a distribution that is known up to a normalizing constant: 

$$
\pi(x) = \frac{\gamma(x)}{\int \gamma(x) dx}
$$

Using the importance sampling approach with proposal density, $q(x)$: 

$$
\begin{aligned}
\pi(x) &= \frac{\frac{\gamma(x)}{q(x)}q(x)}{\int \frac{\gamma(x)}{q(x)}q(x) dx} \\
       &= \frac{w(x)q(x)}{\int w(x)q(x) dx}
\end{aligned}
$$

Let $\{X^{(i)}\}_{i=1}^N$ be $N$ samples from the proposal density. The empirical representation of $q(x)$ is then:

$$
\hat{q}(dx) = \frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx)
$$

Then the approximation of $\pi(x)$ becomes: 

$$
\begin{aligned}
\hat{\pi}(dx) &= \frac{w(x)\hat{q}(x)}{\int w(x)\hat{q}(x) dx} \\
             &= \frac{w(x)\frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx)}{\int w(x) \frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx) dx} \\
             &= \text{\textbf{HOW DO YOU GET TO THE NEXT STEP??}} \\
             &= \frac{\sum_{i=1}^N w(X^{(i)})\delta_{X^{(i)}}(dx)}{\frac{1}{N} \sum_{i=1}^N w(X^{(i)})}\\
\end{aligned}
$$

## Particle Fitlering

Particle filtering is a variant of importance sampling where we sequentially update the filtering distribution using weighted samples. However

---

<!-- ## Overall Problem 

I find that the combination of math and code makes algorithms much easier to understand, so here's the math. I'll mainly follow the notation from [this](https://www.stats.ox.ac.uk/~doucet/doucet_defreitas_gordon_smcbookintro.pdf) paper, but will only write down the neccessities. 

The latent states, $X_t$ are modelled as a Markov process with initial state $p(x_0)$ and transition equation $p(x_t \mid x_{t-1})$. The observed data, $Y_t$, is assumed to be conditionally independent given the hidden state at time $t$, $X_t$, and has density $p(Y_t \mid X_t)$. The model is completely specified by the following: 

$$
\begin{aligned}
X_0 \sim p(x_0) & \qquad \qquad \text{Initial state} \\
p(X_t \mid X_{t-1}) &  \qquad \qquad \text{Transition density} \\
p(Y_t \mid X_t) & \qquad \qquad \text{Marginal of $Y_t \mid X_t$?}
\end{aligned}
$$

The aim is to estimate the posterior distribution of the latent states, $p(X_t \mid Y_t)$, which we use the bootstrap particle filter for. 


## Bootstrap Particle Filter 

The key idea behind particle filtering comes from importance sampling. In importance sampling, we empirically approximate a distribution, $p(x \mid y)$ by sampling from a proposal distribution, $q(x \mid y)$ and re-weighting the samples according to: 

$$ 

In the bootstrap particle filter, we use the transition density as the proposal density in the importance samling step.

Model:

$$ x_t = \frac{1}{2}x_{t-1} + \frac{25x_{t-1}}{1 + x_{t-1}^2} + 8cos(1.2t) + v_t $$

$$ y_t = \frac{x_t^2}{20} + w_t $$

$$ x_0 \sim N(0, \sigma_1^2) $$

$$ w_t \sim N(0, 1) $$

$$ v_k \sim N(0, \sigma_k^2) $$


Outline of SMC algorithm: 

* Initialization: 
    * For $i = 1, ..., N$, sample $x_0^{(i)} \sim p(x_0)$ and set $t = 1$.
    
* Importance sampling step: 
    * For $i = 1, ..., N$, sample $x_t \sim p(x_t \mid x_{t-1}^{(i)})$ and inlcude in $x_{0:t}$
    * For $i = 1, ..., N$, evaluate the importance weights:
    $$ w_t^{(i)} = p(y_t \mid x_t^{(i)}) $$
    * Normalize importance weights
    
* Selection step: 
    * Resample with replacement $N$ particles $(x_{0:t}^{(i)}, i = 1, ..., N)$ according to $w_t^{(i)}$


## Questions to answer

- Setup a simple bootstrap filter with the math of a latent variable model 
- How to deal with particle degeneracy and impoverishment? When I run the resampling step, the same particles are resampled, so we still end up with just 1 particle

#### Bonus 

- How is parameter inference done with SMC


# Particle Filtering

Particle filters are a class of Monte Carlo methods used to approximate the filtering distribution \(p(x_t \mid y_{0:t})\) and the log-likelihood, \(l(\theta)\) by propagating and re-weighting particles. At timepoint, \(t\), we sample \(X_t\) conditional on particles from the previous timepoint \(X_t \sim f(X_t \mid X_{t-1}, \theta)\) using the transition density. These new particles are then re-weighted according to the current observations, \(Y_t\), using the measurement model, \(w_t = g(Y_t \mid X_t, \theta)\). 

A key ingredient to these methods is the use of a resampling step to re-weight particles at certain timepoints.


## Importance Sampling

- https://ib.berkeley.edu/labs/slatkin/eriq/classes/guest_lect/mc_lecture_notes.pdf
- https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/03/10/notes-lecture6.html
- https://bjlkeng.github.io/posts/importance-sampling-and-estimating-marginal-likelihood-in-variational-autoencoders/


## SMC

- [OG SMC tutorial](https://www.cs.ubc.ca/~arnaud/doucet_johansen_tutorialPF.pdf)
- https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/03/17/notes-lecture8.html
- https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/03/15/notes-lecture7.html
- https://umbertopicchini.wordpress.com/2016/10/19/sequential-monte-carlo-bootstrap-filter/

 -->
