---
layout: post
title: "State-Space Models and Particle Filtering"
date: 2022-11-28 2:22
comments: true
author: "Jonathan Ramkissoon"
math: true
summary: Building up to particle filtering for the Bayesian filtering problem
---

In this post I introduce state-space (latent variable) models and explain the filtering problem. We'll then see how importance sampling and particle filtering are used to do inference on this class of models. 

## State Space Models 

State-space models are a general class of latent variable models widely used in engineering, economics and finance to model the evolution of dynamic systems. They are characterized by an unobserved [discrete-time Markov process](https://en.wikipedia.org/wiki/Discrete-time_Markov_chain), $X_t, t \ge 0$ and observations, $Y_t, t \ge 1$. In these models, we assume that $Y_t$ is conditionally independent given $X_t$, and both the transition density for the Markov process, $f(X_t \mid X_{t-1})$ and the observation model, $g(Y_t \mid X_t)$ are given. 

These densities are parameterzied by $\Theta$, and parameter inference on these models is concerned with the estimation of $\Theta$. 

<div class='figure' align="center">
    <img src="/assets/state-space-model.png" width="90%">
    <div class='caption' width="40%" height="40%">
        <p> Visual representation of a generic state-space model. $X_t$ is the state of the system at time $t$, which we don't have "access" to, and $Y_t$ is the observation of the system. </p>
    </div>
</div>

A very simple SSM is a random-walk + noise: 

$$
\begin{align*}
x_t &= x_{t-1} + \epsilon_{t-1}, \qquad \epsilon_t \sim N(0, \sigma^2_{\epsilon}) \\
y_t &= x_t + r_t, \qquad r_t \sim N(0, \sigma^2_{r}) \\ 
\end{align*}
$$

```python
N = 250
sigma2_eps = np.sqrt(0.5)
sigma2_r = np.sqrt(1.2)
eps = np.random.normal(scale=sigma2_eps, size=N)
r = np.random.normal(scale=sigma2_r, size=N)

x = np.cumsum(eps)
y = x + r

fig, ax = plt.subplots(figsize=(12, 5))
plt.plot(x, label="Latent states")
plt.scatter(np.arange(N), y, s=3, color="firebrick", label="Observations")
plt.legend();
```

<div class='figure' align="center">
    <img src="/assets/random-walk-noise.png" width="90%">
</div>


Practitioners are typically interested in either parameter estimation or estimation of the latent states, $X_t$. For example, a common usecase of these models in engineering is for object tracking, where we only have access to a noisy measurement of the object's position at a point in time. In this case, the latent state is the exact position of the object, which we are more interested in estimating compared to the model parameters, $\Theta$. This problem of estimating the latent states is called the Bayesian filtering problem.

At this point you may wonder why I have made the distinction between estimation of parameters and latent states, since we can't really have one without the other. Actually, we can. There are some methods for parameter inference that lend well to cases where we don't care about the latent states, and therefore these are integrated out. To see this, consider the likelihood function for the state space model above: 

$$
\begin{align*}
\mathcal{L}(\Theta \mid Y_{1:T}) &= \int \left[ \pi(X_0) \prod_{t=0}^T g(Y_t \mid X_t, \Theta) \prod_{n=1}^T f(X_n \mid X_{n=1}, \Theta) \right] dX_{0:T}
\end{align*}
$$

If this integral could be approximated somehow, we can bypass the filtering problem and directly maximize the likelihood function to find the MLE. Anyway, that's enough of a tangent. 

### Bayesian Filtering

Bayesian filtering is the problem of estimating the marginal posterior of the state $X_t$ given all previous observations, $Y_{1:t}$, $p(X_t \mid Y_{1:t})$. Note that this distribution is in some sense (not really) the reverse of the observation model, but does not follow any Markov or conditional independence assumptions. However, the conditional independence and Markov assumptions can be used to construct recursive definitions of the quantities we are interested in. [Bayesian Filtering and Smoothing](https://users.aalto.fi/~ssarkka/pub/bfs_book_2023_online.pdf) does a good job explaining these recursive equations for computing the predictive distribution, $p(X_t \mid Y_{1:t-1})$ and filtering distribution, $p(X_t \mid Y_{1:t})$: 

$$
\begin{align*}
p(X_t \mid Y_{1:t-1}) &= \int f(x_t \mid x_{t-1}) g(x_{t-1} \mid y_{1:t-1}) dx_{t-1} \\
p(X_t \mid Y_{1:t}) &= \frac{1}{Z_t} g(y_t \mid x_t) p(x_t \mid y_{1:t-1}) \\
\end{align*}
$$

Where $Z_t$ is a normalizing constant. 

The question now is how do we actually "find" these distributions in practice? I say "find" here because we would really be interested in a closed form solution, but if that isn't available we'll take the next best thing. It turns out that when the underlying dynamics are linear and Gaussian, as in our random walk + noise example, the Kalman filter provides a closed form for the filtering distribution. However, if the underlying dynamics are non-linear but still Gaussian, we no longer have a closed form solution but can approximate the filtering distribution with an extended Kalman filter. The final case is where the underlying dynamics are non-linear and the filtering distribution is non-Gaussian. For these cases we need particle filters. 

## Particle Filtering

In the bootstrap particle filter, we use the transition density as the proposal density in the importance samling step.

Model:

$$ x_t = \frac{1}{2}x_{t-1} + \frac{25x_{t-1}}{1 + x_{t-1}^2} + 8cos(1.2t) + v_t $$

$$ y_t = \frac{x_t^2}{20} + w_t $$

$$ x_0 \sim N(0, \sigma_1^2) $$

$$ w_t \sim N(0, 1) $$

$$ v_k \sim N(0, \sigma_k^2) $$


Outline of SMC algorithm: 

* Initialization: 
    * For $i = 1, ..., N$, sample $x_0^{(i)} \sim p(x_0)$ and set $t = 1$.
    
* Importance sampling step: 
    * For $i = 1, ..., N$, sample $x_t \sim p(x_t \mid x_{t-1}^{(i)})$ and inlcude in $x_{0:t}$
    * For $i = 1, ..., N$, evaluate the importance weights:
    $$ w_t^{(i)} = p(y_t \mid x_t^{(i)}) $$
    * Normalize importance weights
    
* Selection step: 
    * Resample with replacement $N$ particles $(x_{0:t}^{(i)}, i = 1, ..., N)$ according to $w_t^{(i)}$


#### Approximating Distrbituions with Importance Sampling 

Importance sampling gives us a way of approximating integrals, however in the filtering problem we are interested in estimating a distribution. We can use the fact that any distribution, $\pi(x)$, can be expressed as a sum of Dirac delta functions. Suppose $\{X^{(i)}\}_{i=1}^N$ are samples from $\pi(x)$, then the empirical representation of $\pi(x)$ is:

$$
\hat{\pi}^N(dx) = \frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx)
$$

Where $\delta_{X}(A)$ is the Dirac measure, defined as: 


$$
\delta_{X}(A) =
\begin{cases}
1 \qquad X \in A,\\
0 \qquad X \notin A
\end{cases}
$$

As an aside, I'll quickly review how this empirical representation can be used in the importance sampling context, presented in [this post](/_posts/2022-10-22-importance-sampling.md).

Suppose we want to approximate a distribution that is known up to a normalizing constant: 

$$
\pi(x) = \frac{\gamma(x)}{\int \gamma(x) dx}
$$

Using the importance sampling approach with proposal density, $q(x)$: 

$$
\begin{aligned}
\pi(x) &= \frac{\frac{\gamma(x)}{q(x)}q(x)}{\int \frac{\gamma(x)}{q(x)}q(x) dx} \\
       &= \frac{w(x)q(x)}{\int w(x)q(x) dx}
\end{aligned}
$$

Let $\{X^{(i)}\}_{i=1}^N$ be $N$ samples from the proposal density. The empirical representation of $q(x)$ is then:

$$
\hat{q}(dx) = \frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx)
$$

Then the approximation of $\pi(x)$ becomes: 

$$
\begin{aligned}
\hat{\pi}(dx) &= \frac{w(x)\hat{q}(x)}{\int w(x)\hat{q}(x) dx} \\
             &= \frac{w(x)\frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx)}{\int w(x) \frac{1}{N} \sum_{i=1}^N \delta_{X^{(i)}}(dx) dx} \\
             &= \text{\textbf{HOW DO YOU GET TO THE NEXT STEP??}} \\
             &= \frac{\sum_{i=1}^N w(X^{(i)})\delta_{X^{(i)}}(dx)}{\frac{1}{N} \sum_{i=1}^N w(X^{(i)})}\\
\end{aligned}
$$

---

<!-- ## Overall Problem 

---

## State-Space Models

State-space models (also called hidden Markov-models) are a general class of latent-variable models, characterized by an unobserved discrete-time Markov process, ${X}_{t \ge 0}$, and observations, ${Y_t }_{t\ge 0}$. In these models, $Y_t$ is conditionally independent given $X_t$. 

A state-space model is fully specified by the following two distributions, namely the transition density and measurement model respectively. Both of which are parameterized by static parameters, $\theta$:

$$
X_t \mid X_{t-1} \sim f(X \mid X_{t-1}, \theta), \\
Y_t \mid Y_t \sim g(Y \mid X_t, \theta)
$$


<div class='figure' align="center">
    <img src="../assets/SSM.png" width="90%">
    <div class='caption' width="40%" height="40%">
        <p> Graphical representation of a state-space model  </p>
    </div>
</div>

We are generally interested in the estimation of the latent process, $\{X_t\}_{t \ge 0}$, or the static parameters, $\theta$, or both, conditional on the observed data, $Y_{1:t}$. The former is the estimation of $p(X_t \mid Y_{1:t}), 1 \le t \le T$, which is the Bayesian filtering problem. The latter is the estimation of the posterior $p(\theta \mid Y_{1:T}, X_{0:T})$, which is the standard parameter inference problem.

The challenge posed by the filtering problem is in the efficient estimation of the filtering distribution, $p(X_t \mid Y_{1:t})$. As we will see in the next sections, importance sampling provides a way of estimating an arbitrary distribution, $p(X)$ using weighted samples from a proposal, but naively applying this to filtering problem is inefficeint.

The parameter inference problem is challenging because for non-linear, non-Gaussian state-space models the likelihood function is intractable. Calculating this likelihood involves integrating out all the latent states, $X_t$, as follows: 

$$
L(\theta \mid Y_{0:T}) = \int \left[\pi(X_0) \cdot \prod_{n=0}^T g(Y_n \mid X_n, \theta) \cdot \prod_{n=1}^T f(X_n \mid X_{n-1}, \theta)\right] d X_{0:T}.
$$

Where $\pi(X_0)$ is a prior on the initial state of the latent process. Again, importance sampling provides a way of approximating integrals, but will be grossly inefficient for something as complex and high-dimensional as this.

I find that the combination of math and code makes algorithms much easier to understand, so here's the math. I'll mainly follow the notation from [this](https://www.stats.ox.ac.uk/~doucet/doucet_defreitas_gordon_smcbookintro.pdf) paper, but will only write down the neccessities. 

The latent states, $X_t$ are modelled as a Markov process with initial state $p(x_0)$ and transition equation $p(x_t \mid x_{t-1})$. The observed data, $Y_t$, is assumed to be conditionally independent given the hidden state at time $t$, $X_t$, and has density $p(Y_t \mid X_t)$. The model is completely specified by the following: 

$$
\begin{aligned}
X_0 \sim p(x_0) & \qquad \qquad \text{Initial state} \\
p(X_t \mid X_{t-1}) &  \qquad \qquad \text{Transition density} \\
p(Y_t \mid X_t) & \qquad \qquad \text{Marginal of $Y_t \mid X_t$?}
\end{aligned}
$$

The aim is to estimate the posterior distribution of the latent states, $p(X_t \mid Y_t)$, which we use the bootstrap particle filter for. 


## Bootstrap Particle Filter 

The key idea behind particle filtering comes from importance sampling. In importance sampling, we empirically approximate a distribution, $p(x \mid y)$ by sampling from a proposal distribution, $q(x \mid y)$ and re-weighting the samples according to: 

$$ 

In the bootstrap particle filter, we use the transition density as the proposal density in the importance samling step.

Model:

$$ x_t = \frac{1}{2}x_{t-1} + \frac{25x_{t-1}}{1 + x_{t-1}^2} + 8cos(1.2t) + v_t $$

$$ y_t = \frac{x_t^2}{20} + w_t $$

$$ x_0 \sim N(0, \sigma_1^2) $$

$$ w_t \sim N(0, 1) $$

$$ v_k \sim N(0, \sigma_k^2) $$


Outline of SMC algorithm: 

* Initialization: 
    * For $i = 1, ..., N$, sample $x_0^{(i)} \sim p(x_0)$ and set $t = 1$.
    
* Importance sampling step: 
    * For $i = 1, ..., N$, sample $x_t \sim p(x_t \mid x_{t-1}^{(i)})$ and inlcude in $x_{0:t}$
    * For $i = 1, ..., N$, evaluate the importance weights:
    $$ w_t^{(i)} = p(y_t \mid x_t^{(i)}) $$
    * Normalize importance weights
    
* Selection step: 
    * Resample with replacement $N$ particles $(x_{0:t}^{(i)}, i = 1, ..., N)$ according to $w_t^{(i)}$


## Questions to answer

- Setup a simple bootstrap filter with the math of a latent variable model 
- How to deal with particle degeneracy and impoverishment? When I run the resampling step, the same particles are resampled, so we still end up with just 1 particle

#### Bonus 

- How is parameter inference done with SMC


# Particle Filtering

Particle filters are a class of Monte Carlo methods used to approximate the filtering distribution \(p(x_t \mid y_{0:t})\) and the log-likelihood, \(l(\theta)\) by propagating and re-weighting particles. At timepoint, \(t\), we sample \(X_t\) conditional on particles from the previous timepoint \(X_t \sim f(X_t \mid X_{t-1}, \theta)\) using the transition density. These new particles are then re-weighted according to the current observations, \(Y_t\), using the measurement model, \(w_t = g(Y_t \mid X_t, \theta)\). 

A key ingredient to these methods is the use of a resampling step to re-weight particles at certain timepoints.


## Importance Sampling

- https://ib.berkeley.edu/labs/slatkin/eriq/classes/guest_lect/mc_lecture_notes.pdf
- https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/03/10/notes-lecture6.html
- https://bjlkeng.github.io/posts/importance-sampling-and-estimating-marginal-likelihood-in-variational-autoencoders/


## SMC

- [OG SMC tutorial](https://www.cs.ubc.ca/~arnaud/doucet_johansen_tutorialPF.pdf)
- https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/03/17/notes-lecture8.html
- https://www.stat.ubc.ca/~bouchard/courses/stat520-sp2014-15/lecture/2015/03/15/notes-lecture7.html
- https://umbertopicchini.wordpress.com/2016/10/19/sequential-monte-carlo-bootstrap-filter/

 -->
