{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe7ff26",
   "metadata": {},
   "source": [
    "# Transformers and Attention "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2738edcd",
   "metadata": {},
   "source": [
    "**Goal 1: Implement a self-attention class that uses bi-directional attention**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ec43782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f13caae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention (nn.Module):\n",
    "    \"\"\"\n",
    "    Implementation of self/cross bi-directional/uni-directional attention. To use this for self attention, \n",
    "    pass the same input and context size on initialization. To use bi-directional/uni-directional \n",
    "    attention, pass different masks to the forward method\n",
    "    \n",
    "    Args: \n",
    "        - X: sequence to find contextual representation of, \\in \\mathcal{R}^{d_{x}, l}\n",
    "        - Z: sequence to attent to, \\in \\mathcal{R}^{d_{z}, l}\n",
    "    \n",
    "    Returns: \n",
    "        - X_contextual: Updated embeddings of tokens in X with information from tokens in Z incorporated \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__ (self, inp_embd_size, context_embd_size, attn_embd_size, out_embd_size, **kwargs):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn_embd_size = attn_embd_size\n",
    "        self.out_embd_size = out_embd_size\n",
    "        \n",
    "        self.W_q = nn.Linear(in_features=inp_embd_size, out_features=self.attn_embd_size) # query embedding \n",
    "        self.W_k = nn.Linear(in_features=context_embd_size, out_features=self.attn_embd_size) # key embedding\n",
    "        self.W_v = nn.Linear(in_features=context_embd_size, out_features=self.out_embd_size)\n",
    "        \n",
    "    def forward (self, primary_seq, context_seq, attn_mask, **kwargs):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            - primary_seq: Sequence to find contextual embeddings of. Shape (inp_embd_size, context_maxlen)\n",
    "            - context_seq: Contextual sequence of shape (context_embd_size, context_maxlen)\n",
    "            - attn_mask: Determines which of the tokens in the context to be masked\n",
    "        Q = W_q @ X\n",
    "        K = W_k @ Z\n",
    "        V = W_v @ Z\n",
    "        X_contextual = softmax(QK^T / sqrt(attn_embd_size)) @ V\n",
    "        \"\"\"\n",
    "        Q = self.W_q(X.T)\n",
    "        K = self.W_k(Z.T)\n",
    "        V = self.W_v(Z.T)\n",
    "        \n",
    "        unnormalized_weights = Q @ K.T / self.attn_embd_size**0.5\n",
    "        unnormalized_weights[:, attn_mask == 0] = -1e10\n",
    "        \n",
    "        attn_weights = F.softmax(unnormalized_weights, dim=0)\n",
    "        contextual_embd = attn_weights @ V\n",
    "        \n",
    "        return contextual_embd.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43b40811",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embd_size = 10\n",
    "context_embd_size = 13\n",
    "max_len = 5\n",
    "\n",
    "sa = Attention(inp_embd_size=inp_embd_size,\n",
    "               context_embd_size=context_embd_size,\n",
    "               attn_embd_size=15,\n",
    "               out_embd_size=25)\n",
    "\n",
    "X = torch.rand((inp_embd_size, max_len))\n",
    "Z = torch.rand((context_embd_size, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b9fbbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2675, -0.2833, -0.2504, -0.2697, -0.2771],\n",
       "        [ 0.8851,  0.9592,  0.8076,  0.8960,  0.9251],\n",
       "        [-0.1002, -0.1057, -0.0918, -0.1008, -0.1032],\n",
       "        [ 0.2821,  0.3092,  0.2548,  0.2873,  0.2978],\n",
       "        [-0.1855, -0.1995, -0.1699, -0.1888, -0.1943],\n",
       "        [-0.0884, -0.0966, -0.0830, -0.0892, -0.0929],\n",
       "        [ 0.8463,  0.9158,  0.7716,  0.8572,  0.8848],\n",
       "        [-0.0792, -0.0911, -0.0689, -0.0811, -0.0864],\n",
       "        [ 0.5071,  0.5524,  0.4594,  0.5125,  0.5315],\n",
       "        [-0.4519, -0.4914, -0.4097, -0.4590, -0.4738],\n",
       "        [-0.1769, -0.1870, -0.1658, -0.1780, -0.1817],\n",
       "        [-0.7086, -0.7620, -0.6555, -0.7165, -0.7361],\n",
       "        [ 0.3986,  0.4333,  0.3629,  0.4051,  0.4170],\n",
       "        [-0.0143, -0.0163, -0.0122, -0.0135, -0.0138],\n",
       "        [-0.1992, -0.2188, -0.1764, -0.2036, -0.2107],\n",
       "        [ 0.4346,  0.4655,  0.4013,  0.4380,  0.4525],\n",
       "        [-0.6479, -0.7024, -0.5956, -0.6568, -0.6778],\n",
       "        [-0.1916, -0.2033, -0.1793, -0.1907, -0.1982],\n",
       "        [-0.5944, -0.6480, -0.5397, -0.6010, -0.6222],\n",
       "        [ 0.9141,  0.9935,  0.8326,  0.9266,  0.9589],\n",
       "        [ 0.3519,  0.3756,  0.3313,  0.3513,  0.3644],\n",
       "        [-0.2521, -0.2797, -0.2214, -0.2592, -0.2673],\n",
       "        [-0.3135, -0.3436, -0.2818, -0.3197, -0.3321],\n",
       "        [-0.1813, -0.1937, -0.1694, -0.1830, -0.1871],\n",
       "        [ 0.8080,  0.8746,  0.7382,  0.8203,  0.8458]],\n",
       "       grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa(X, Z, attn_mask = torch.tensor([1, 1, 1, 1,1,0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0a463",
   "metadata": {},
   "source": [
    "# Adding Context to Short-Text Inputs\n",
    "\n",
    "### 1: Sentiment Analysis with Contextual Information\n",
    "\n",
    "Traditional sentiment analysis starts with labeled sentiment text data and follows by fitting a model to predict sentiment. Current SoTA models in NLP use local contextual information by attending to different parts of the input. In a dynamic setting, the same input could change from having positive sentiment to negative sentiment depending on public perception. The goal of this post is to build a model that can capture and incorporate global contextual information into sentiment prediction.\n",
    "\n",
    "- Input: BERT encoded vector of a tweet\n",
    "- Context: $n$ most recent tweets before the input\n",
    "- Cross-attention between input and context to find a contextual representation of the input sequence\n",
    "- Classifier head on-top of the contextual representation\n",
    "\n",
    "**Goal 1:** Using cross-attention, create a contextual representation of a tweet with context being the previous $n$ tweets.\n",
    "\n",
    "\n",
    "### 2: Contextual Company Embeddings using News\n",
    "\n",
    "Can cross-attention be used to create contextual embeddings for company names using the news? \n",
    "\n",
    "**Goal 1:** Get contextual representation of one company where the context is news in a topic. \n",
    "\n",
    "\n",
    "### Questions\n",
    "\n",
    "- Can I train a model with an attention head on-top of an LLM to make contextual classifications?\n",
    "- How can an attention head be used to supplement short-inputs? \n",
    "- How is context related to simply adding an additional input? Is there a difference?\n",
    "- Should self-attention or cross-attention be used here? Intuitively, what would be the difference in the embeddings? I am assuming cross-attention gives more weight to the context sequence and less weight to the primary sequence/tokens. My ultimate goal is to add context to short-text inputs. \n",
    "- Compare self-attention VS cross-attention for adding context to short-text inputs. How to evaluate the embeddings? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68a2d693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 5000)\n",
    "pd.set_option(\"display.max_columns\", 5000)\n",
    "pd.set_option(\"max_colwidth\", 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "331fc554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28264, 7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2_/p8bp092s40vffb3hypvrdkjw0000gp/T/ipykernel_4898/2669000627.py:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  news = pd.read_csv(\"/Users/jramkissoon/Documents/data/blog/financial-tweets/stockerbot-export.csv\",\n",
      "Skipping line 731: expected 8 fields, saw 13\n",
      "Skipping line 2836: expected 8 fields, saw 15\n",
      "Skipping line 3058: expected 8 fields, saw 12\n",
      "Skipping line 3113: expected 8 fields, saw 12\n",
      "Skipping line 3194: expected 8 fields, saw 17\n",
      "Skipping line 3205: expected 8 fields, saw 17\n",
      "Skipping line 3255: expected 8 fields, saw 17\n",
      "Skipping line 3520: expected 8 fields, saw 17\n",
      "Skipping line 4078: expected 8 fields, saw 17\n",
      "Skipping line 4087: expected 8 fields, saw 17\n",
      "Skipping line 4088: expected 8 fields, saw 17\n",
      "Skipping line 4499: expected 8 fields, saw 12\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VIDEO: “I was in my office. I was minding my own business...” –David Solomon tells $GS interns how he learned he wa… https://t.co/QClAITywXV</td>\n",
       "      <td>Wed Jul 18 21:33:26 +0000 2018</td>\n",
       "      <td>GoldmanSachs</td>\n",
       "      <td>GS</td>\n",
       "      <td>The Goldman Sachs</td>\n",
       "      <td>https://twitter.com/i/web/status/1019696670777503745</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The price of lumber $LB_F is down 22% since hitting its YTD highs. The Macy's $M turnaround is still happening.… https://t.co/XnKsV4De39</td>\n",
       "      <td>Wed Jul 18 22:22:47 +0000 2018</td>\n",
       "      <td>StockTwits</td>\n",
       "      <td>M</td>\n",
       "      <td>Macy's</td>\n",
       "      <td>https://twitter.com/i/web/status/1019709091038547968</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who says the American Dream is dead? https://t.co/CRgx19x7sA</td>\n",
       "      <td>Wed Jul 18 22:32:01 +0000 2018</td>\n",
       "      <td>TheStreet</td>\n",
       "      <td>AIG</td>\n",
       "      <td>American</td>\n",
       "      <td>https://buff.ly/2L3kmc4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barry Silbert is extremely optimistic on bitcoin -- but predicts that 99% of new crypto entrants are “going to zero… https://t.co/mGMVo2cZgY</td>\n",
       "      <td>Wed Jul 18 22:52:52 +0000 2018</td>\n",
       "      <td>MarketWatch</td>\n",
       "      <td>BTC</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>https://twitter.com/i/web/status/1019716662587740160</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How satellites avoid attacks and space junk while circling the Earth https://t.co/aHzIV3Lqp5 #paid @Oracle https://t.co/kacpqZWiDJ</td>\n",
       "      <td>Wed Jul 18 23:00:01 +0000 2018</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>ORCL</td>\n",
       "      <td>Oracle</td>\n",
       "      <td>http://on.forbes.com/6013DqDDU</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                           text  \\\n",
       "0  VIDEO: “I was in my office. I was minding my own business...” –David Solomon tells $GS interns how he learned he wa… https://t.co/QClAITywXV   \n",
       "1      The price of lumber $LB_F is down 22% since hitting its YTD highs. The Macy's $M turnaround is still happening.… https://t.co/XnKsV4De39   \n",
       "2                                                                                  Who says the American Dream is dead? https://t.co/CRgx19x7sA   \n",
       "3  Barry Silbert is extremely optimistic on bitcoin -- but predicts that 99% of new crypto entrants are “going to zero… https://t.co/mGMVo2cZgY   \n",
       "4            How satellites avoid attacks and space junk while circling the Earth https://t.co/aHzIV3Lqp5 #paid @Oracle https://t.co/kacpqZWiDJ   \n",
       "\n",
       "                        timestamp        source symbols      company_names  \\\n",
       "0  Wed Jul 18 21:33:26 +0000 2018  GoldmanSachs      GS  The Goldman Sachs   \n",
       "1  Wed Jul 18 22:22:47 +0000 2018    StockTwits       M             Macy's   \n",
       "2  Wed Jul 18 22:32:01 +0000 2018     TheStreet     AIG           American   \n",
       "3  Wed Jul 18 22:52:52 +0000 2018   MarketWatch     BTC            Bitcoin   \n",
       "4  Wed Jul 18 23:00:01 +0000 2018        Forbes    ORCL             Oracle   \n",
       "\n",
       "                                                    url  verified  \n",
       "0  https://twitter.com/i/web/status/1019696670777503745      True  \n",
       "1  https://twitter.com/i/web/status/1019709091038547968      True  \n",
       "2                               https://buff.ly/2L3kmc4      True  \n",
       "3  https://twitter.com/i/web/status/1019716662587740160      True  \n",
       "4                        http://on.forbes.com/6013DqDDU      True  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news = pd.read_csv(\"/Users/jramkissoon/Documents/data/blog/financial-tweets/stockerbot-export.csv\", \n",
    "                   error_bad_lines=False)\n",
    "news = news.drop(columns=[\"id\"])\n",
    "print(news.shape)\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1d1a7290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>source</th>\n",
       "      <th>symbols</th>\n",
       "      <th>company_names</th>\n",
       "      <th>url</th>\n",
       "      <th>verified</th>\n",
       "      <th>RT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>RT @Optionsonar1: $260000.00 of bearish unusual option activity detected for $SYF</td>\n",
       "      <td>Mon Jul 16 16:18:34 +0000 2018</td>\n",
       "      <td>teebizy</td>\n",
       "      <td>SYF</td>\n",
       "      <td>Synchrony Financial</td>\n",
       "      <td>http://optionsonar.com/unusual-option-activity/syf/latest-trades</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>$WLTW Earnings volatility concerns drive reinsurance buying Willis Towers Watson survey finds Nasdaq:WLTW</td>\n",
       "      <td>Mon Jul 09 13:11:54 +0000 2018</td>\n",
       "      <td>StockTexts</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>Willis Towers Watson Public Limited Company</td>\n",
       "      <td>http://www.globenewswire.com/news-release/2018/07/09/1534686/0/en/Earnings-volatility-concerns-drive-reinsurance-buying-Willis-Towers-Watson-survey-finds.html</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5443</th>\n",
       "      <td>New UOA detected for $MPC: 1356 $75.0 PUT options expiring 2018-08-17 traded for $4.9 bought on the ask</td>\n",
       "      <td>Fri Jul 13 19:44:01 +0000 2018</td>\n",
       "      <td>liveoptiondata</td>\n",
       "      <td>MPC</td>\n",
       "      <td>Marathon Petroleum Corporation</td>\n",
       "      <td>https://www.optionsonar.com/unusual-option-activity/MPC/latest-trades</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>7/11 50D MA Watch List: $ADSK $MU $OIH $OKTA $BG $KEY $BA $JD $LNG $XME $FXE $GPS $GM $CME $C $EMR $LBTYA $SOGO…</td>\n",
       "      <td>Wed Jul 11 13:00:20 +0000 2018</td>\n",
       "      <td>TradeAcademyCo</td>\n",
       "      <td>JCI</td>\n",
       "      <td>Johnson Controls International plc</td>\n",
       "      <td>https://twitter.com/i/web/status/1017030833352241153</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26406</th>\n",
       "      <td>$DWCH $EBAY $AXP $AA 5 Stocks Moving In Wednesday's After-Hours Session -</td>\n",
       "      <td>Wed Jul 18 21:21:04 +0000 2018</td>\n",
       "      <td>BenzingaMedia</td>\n",
       "      <td>AXP</td>\n",
       "      <td>American Express Company</td>\n",
       "      <td>http://tinyurl.com/ydaqpgxp</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15161</th>\n",
       "      <td>$GG Goldcorp Inc. Option Order Flow Sentiment is 81.9% Bullish.</td>\n",
       "      <td>Tue Jul 17 17:45:42 +0000 2018</td>\n",
       "      <td>MC_OptionTrades</td>\n",
       "      <td>GG</td>\n",
       "      <td>Goldcorp Inc.</td>\n",
       "      <td>https://marketchameleon.com/Overview/GG/OptionOrderSentiment/</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10450</th>\n",
       "      <td>Fluor Co. $NEW $FLR Expected to Announce Earnings of $0.69 Per Share</td>\n",
       "      <td>Mon Jul 16 15:57:55 +0000 2018</td>\n",
       "      <td>WatchlistN</td>\n",
       "      <td>FLR</td>\n",
       "      <td>Fluor Corporation</td>\n",
       "      <td>http://zpr.io/6XyTv</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>$CERN $HSIC $PAYX Bearish MACD crossover</td>\n",
       "      <td>Tue Jul 17 13:01:26 +0000 2018</td>\n",
       "      <td>themaxpain</td>\n",
       "      <td>HSIC</td>\n",
       "      <td>Henry Schein</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>Stericycle Inc $SRCL Given Consensus Recommendation of “Hold” by Brokerages</td>\n",
       "      <td>Tue Jul 10 12:33:59 +0000 2018</td>\n",
       "      <td>TickerReport</td>\n",
       "      <td>SRCL</td>\n",
       "      <td>Stericycle</td>\n",
       "      <td>http://tickerreport.com/?p=3626453</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6695</th>\n",
       "      <td>Credit Suisse Group Boosts Nordstrom $JWN Price Target to $52.00</td>\n",
       "      <td>Sat Jul 14 23:26:49 +0000 2018</td>\n",
       "      <td>MareaInformativ</td>\n",
       "      <td>JWN</td>\n",
       "      <td>Nordstrom</td>\n",
       "      <td>http://www.mareainformativa.com/?p=442513</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    text  \\\n",
       "10541                                RT @Optionsonar1: $260000.00 of bearish unusual option activity detected for $SYF     \n",
       "287           $WLTW Earnings volatility concerns drive reinsurance buying Willis Towers Watson survey finds Nasdaq:WLTW    \n",
       "5443            New UOA detected for $MPC: 1356 $75.0 PUT options expiring 2018-08-17 traded for $4.9 bought on the ask    \n",
       "2003   7/11 50D MA Watch List: $ADSK $MU $OIH $OKTA $BG $KEY $BA $JD $LNG $XME $FXE $GPS $GM $CME $C $EMR $LBTYA $SOGO…    \n",
       "26406                                         $DWCH $EBAY $AXP $AA 5 Stocks Moving In Wednesday's After-Hours Session -    \n",
       "15161                                                   $GG Goldcorp Inc. Option Order Flow Sentiment is 81.9% Bullish.    \n",
       "10450                                              Fluor Co. $NEW $FLR Expected to Announce Earnings of $0.69 Per Share    \n",
       "13769                                                                           $CERN $HSIC $PAYX Bearish MACD crossover   \n",
       "1029                                        Stericycle Inc $SRCL Given Consensus Recommendation of “Hold” by Brokerages    \n",
       "6695                                                   Credit Suisse Group Boosts Nordstrom $JWN Price Target to $52.00    \n",
       "\n",
       "                            timestamp           source symbols  \\\n",
       "10541  Mon Jul 16 16:18:34 +0000 2018          teebizy     SYF   \n",
       "287    Mon Jul 09 13:11:54 +0000 2018       StockTexts    WLTW   \n",
       "5443   Fri Jul 13 19:44:01 +0000 2018   liveoptiondata     MPC   \n",
       "2003   Wed Jul 11 13:00:20 +0000 2018   TradeAcademyCo     JCI   \n",
       "26406  Wed Jul 18 21:21:04 +0000 2018    BenzingaMedia     AXP   \n",
       "15161  Tue Jul 17 17:45:42 +0000 2018  MC_OptionTrades      GG   \n",
       "10450  Mon Jul 16 15:57:55 +0000 2018       WatchlistN     FLR   \n",
       "13769  Tue Jul 17 13:01:26 +0000 2018       themaxpain    HSIC   \n",
       "1029   Tue Jul 10 12:33:59 +0000 2018     TickerReport    SRCL   \n",
       "6695   Sat Jul 14 23:26:49 +0000 2018  MareaInformativ     JWN   \n",
       "\n",
       "                                     company_names  \\\n",
       "10541                          Synchrony Financial   \n",
       "287    Willis Towers Watson Public Limited Company   \n",
       "5443                Marathon Petroleum Corporation   \n",
       "2003            Johnson Controls International plc   \n",
       "26406                     American Express Company   \n",
       "15161                                Goldcorp Inc.   \n",
       "10450                            Fluor Corporation   \n",
       "13769                                 Henry Schein   \n",
       "1029                                    Stericycle   \n",
       "6695                                     Nordstrom   \n",
       "\n",
       "                                                                                                                                                                  url  \\\n",
       "10541                                                                                                http://optionsonar.com/unusual-option-activity/syf/latest-trades   \n",
       "287    http://www.globenewswire.com/news-release/2018/07/09/1534686/0/en/Earnings-volatility-concerns-drive-reinsurance-buying-Willis-Towers-Watson-survey-finds.html   \n",
       "5443                                                                                            https://www.optionsonar.com/unusual-option-activity/MPC/latest-trades   \n",
       "2003                                                                                                             https://twitter.com/i/web/status/1017030833352241153   \n",
       "26406                                                                                                                                     http://tinyurl.com/ydaqpgxp   \n",
       "15161                                                                                                   https://marketchameleon.com/Overview/GG/OptionOrderSentiment/   \n",
       "10450                                                                                                                                             http://zpr.io/6XyTv   \n",
       "13769                                                                                                                                                             NaN   \n",
       "1029                                                                                                                               http://tickerreport.com/?p=3626453   \n",
       "6695                                                                                                                        http://www.mareainformativa.com/?p=442513   \n",
       "\n",
       "       verified     RT  \n",
       "10541     False   True  \n",
       "287       False  False  \n",
       "5443      False  False  \n",
       "2003      False  False  \n",
       "26406     False  False  \n",
       "15161     False  False  \n",
       "10450     False  False  \n",
       "13769     False  False  \n",
       "1029      False  False  \n",
       "6695      False  False  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news[\"text\"] = news.text.apply(lambda x: re.sub(r\"https://\\S+\", \"\", x))\n",
    "news[\"RT\"] = news.text.apply(lambda x: re.search(\"^RT @.*:\", x) != None)\n",
    "print(news.RT.sum())\n",
    "news.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8ba1b301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22253</th>\n",
       "      <td>Netflix $NFLX just released quarterly 10-Q.  Quarterly net income increased from 127M to 462 Million!!! 400% ⬆️</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22269</th>\n",
       "      <td>#NASDAQ MOST VOLUME  $HMNY -9.09% [Volume: +82.41% ~ 81012800] $AMD -0.53% [Volume: -1.8% ~ 40776700] $MU +0.35…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22273</th>\n",
       "      <td>New article on $NFLX at  Today I went over my bullish and bearish trade ideas from 6/18/18 a…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22346</th>\n",
       "      <td>NOW OFFERING 7 Day FREE Trial to  options day trading team Room or $TWTR feed  $FB $AAPL $NFLX $TSLA $AMZN $GOOGL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22415</th>\n",
       "      <td>When I try to get in on some hot $NFLX calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22429</th>\n",
       "      <td>$MS expecting a $BAC like move when it reported earnings. $CPAH HOD didn't come have to exit before the rugpull.…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22432</th>\n",
       "      <td>Netflix To Bring Comedy To New Sirius XM Channel  $NFLX $SIRI $SPOT $T $AMZN $DIS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22434</th>\n",
       "      <td>With past performance like this how can you not sign up for a Free 7-day trial to  Winning…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22460</th>\n",
       "      <td>{VIDEO} Stock Analysis + Trade Ideas: $TSLA $NFLX $BIDU $BABA $GOOGL $DIS - click link to watch &amp;gt;&amp;gt;…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22502</th>\n",
       "      <td>Tech Sector Buzz: Netflix Earnings Amazon and the App Store $NFLX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     text\n",
       "22253    Netflix $NFLX just released quarterly 10-Q.  Quarterly net income increased from 127M to 462 Million!!! 400% ⬆️ \n",
       "22269   #NASDAQ MOST VOLUME  $HMNY -9.09% [Volume: +82.41% ~ 81012800] $AMD -0.53% [Volume: -1.8% ~ 40776700] $MU +0.35… \n",
       "22273                      New article on $NFLX at  Today I went over my bullish and bearish trade ideas from 6/18/18 a… \n",
       "22346   NOW OFFERING 7 Day FREE Trial to  options day trading team Room or $TWTR feed  $FB $AAPL $NFLX $TSLA $AMZN $GOOGL\n",
       "22415                                                                       When I try to get in on some hot $NFLX calls \n",
       "22429  $MS expecting a $BAC like move when it reported earnings. $CPAH HOD didn't come have to exit before the rugpull.… \n",
       "22432                                   Netflix To Bring Comedy To New Sirius XM Channel  $NFLX $SIRI $SPOT $T $AMZN $DIS\n",
       "22434                        With past performance like this how can you not sign up for a Free 7-day trial to  Winning… \n",
       "22460          {VIDEO} Stock Analysis + Trade Ideas: $TSLA $NFLX $BIDU $BABA $GOOGL $DIS - click link to watch &gt;&gt;… \n",
       "22502                                                 Tech Sector Buzz: Netflix Earnings Amazon and the App Store $NFLX  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verified = news[~news.RT].reset_index(drop=True)\n",
    "verified[verified.symbols ==\"NFLX\"].sort_values(\"timestamp\")[[\"text\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "17b3c0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix earnings expected to be $2. Netflix not having a good quarter. Netflix sees quarterly earnings at $1.2\n"
     ]
    }
   ],
   "source": [
    "input_ = \"Netflix releases earnings numbers of $1\"\n",
    "context_ = '. '.join([\n",
    "    \"Netflix earnings expected to be $2\",\n",
    "    \"Netflix not having a good quarter\",\n",
    "    \"Netflix sees quarterly earnings at $1.2\"\n",
    "])\n",
    "\n",
    "print(context_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e4cbb",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c7679c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel, BertConfig, AdamW, get_linear_schedule_with_warmup\n",
    "import pytorch_lightning as pl\n",
    "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8077441c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf2c367356a4f80a053bc2f96b68294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1132ce4a5bd94f6fb88d5cbf68a852f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3680090f7c08447e94f629740ddc62be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521038c187bd4328b3129e685ae54127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert_base = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualSentimentModel(nn.Module):\n",
    "    def __init__(self, bert_base, num_labels):\n",
    "        super(ContextualSentimentModel, self).__init__()\n",
    "        self.bert_base = bert_base\n",
    "        self.cross_attention = nn.MultiheadAttention(embed_dim=768, num_heads=12)\n",
    "        self.classifier = nn.Linear(768, num_labels)\n",
    "        \n",
    "    def forward(self, inputs, context):\n",
    "        \"\"\"\n",
    "        Args: \n",
    "            - inputs: dictionary with keys corresponding to outputs of tokenizer(...)\n",
    "            - context: dictionary with keys corresponding to outputs of tokenizer(...)\n",
    "        \"\"\"\n",
    "        # input embedding:\n",
    "        input_embd = self.bert_base(input_ids=inputs[\"input_ids\"], \n",
    "                                    attention_mask=inputs[\"attention_mask\"]).last_hidden_state\n",
    "        \n",
    "        # context embedding: \n",
    "        context_embd = self.bert_base(input_ids=context[\"input_ids\"], \n",
    "                                      attention_mask=context[\"attention_mask\"]).last_hidden_state\n",
    "        \n",
    "        # Apply cross-attention\n",
    "        query = input_embd[:, -1, :].unsqueeze(1)  # Use the last token as the query\n",
    "        key = context_embd\n",
    "        attn_output, _ = self.cross_attention(query, key, key, key_padding_mask=(1 - inputs[\"attention_mask\"]))\n",
    "        \n",
    "        # Pass the attended output through the classification head\n",
    "        logits = self.classifier(attn_output.squeeze(1))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c239fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(input_, return_tensors=\"pt\")\n",
    "context = tokenizer(context_, return_tensors=\"pt\")\n",
    "\n",
    "input_encoding = bert_base(**tokenizer(input_, return_tensors=\"pt\"))\n",
    "context_encoding = bert_base(**tokenizer(context_, return_tensors=\"pt\"))\n",
    "\n",
    "input_embd = input_encoding.last_hidden_state\n",
    "context_embd = context_encoding.last_hidden_state\n",
    "\n",
    "cross_attention = nn.MultiheadAttention(embed_dim=768, num_heads=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "657db9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 26, 768])\n",
      "torch.Size([1, 1, 768])\n"
     ]
    }
   ],
   "source": [
    "print(context_embd.shape)\n",
    "print(query.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e0c69103",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[1, 12, 64]' is invalid for input of size 19968",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m key \u001b[38;5;241m=\u001b[39m context_embd\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# attn_output, _ = self.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mcross_attention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/experiments/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/experiments/lib/python3.10/site-packages/torch/nn/modules/activation.py:1167\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights)\u001b[0m\n\u001b[1;32m   1156\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmulti_head_attention_forward(\n\u001b[1;32m   1157\u001b[0m         query, key, value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_dim, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads,\n\u001b[1;32m   1158\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_weight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_proj_bias,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         q_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_proj_weight, k_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_proj_weight,\n\u001b[1;32m   1165\u001b[0m         v_proj_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mv_proj_weight, average_attn_weights\u001b[38;5;241m=\u001b[39maverage_attn_weights)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     attn_output, attn_output_weights \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_head_attention_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_zero_attn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkey_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneed_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mneed_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_attn_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage_attn_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;129;01mand\u001b[39;00m is_batched:\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m), attn_output_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/experiments/lib/python3.10/site-packages/torch/nn/functional.py:5097\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights)\u001b[0m\n\u001b[1;32m   5095\u001b[0m q \u001b[38;5;241m=\u001b[39m q\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(tgt_len, bsz \u001b[38;5;241m*\u001b[39m num_heads, head_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m static_k \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 5097\u001b[0m     k \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbsz\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   5098\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   5099\u001b[0m     \u001b[38;5;66;03m# TODO finish disentangling control flow so we don't do in-projections when statics are passed\u001b[39;00m\n\u001b[1;32m   5100\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m static_k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m==\u001b[39m bsz \u001b[38;5;241m*\u001b[39m num_heads, \\\n\u001b[1;32m   5101\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpecting static_k.size(0) of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbsz \u001b[38;5;241m*\u001b[39m num_heads\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatic_k\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[1, 12, 64]' is invalid for input of size 19968"
     ]
    }
   ],
   "source": [
    "query = input_embd[:, -1, :].unsqueeze(1)  # Use the last token as the query\n",
    "key = context_embd\n",
    "\n",
    "# attn_output, _ = self.\n",
    "cross_attention(query, key, key) # key_padding_mask=(1 - inputs[\"attention_mask\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862463a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentModelLightning(pl.LightningModule):\n",
    "    def __init__(self, model, learning_rate=2e-5, num_training_steps=None, num_warmup_steps=0):\n",
    "        super(SentimentModelLightning, self).__init__()\n",
    "        self.model = model\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_training_steps = num_training_steps\n",
    "        self.num_warmup_steps = num_warmup_steps\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        return self.model(input_ids, attention_mask)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        logits = self(input_ids, attention_mask)\n",
    "        loss = F.cross_entropy(logits, labels)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        accuracy = accuracy_score(labels.cpu(), preds.cpu())\n",
    "        return {\"val_loss\": loss, \"val_accuracy\": accuracy}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_accuracy = sum([x[\"val_accuracy\"] for x in outputs]) / len(outputs)\n",
    "        self.log(\"val_loss\", avg_loss)\n",
    "        self.log(\"val_accuracy\", avg_accuracy)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = AdamW(self.parameters(), lr=self.learning_rate)\n",
    "        scheduler = get_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b5a62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cd20390c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: Apple, Amazon, Tesla, Palantir, DocuSign, Exxon &amp;amp; more</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Buy Las Vegas Sands as travel to Singapore builds, Wells Fargo says</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Piper Sandler downgrades DocuSign to sell, citing elevated risks amid CEO transition</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analysts react to Tesla's latest earnings, break down what's next for electric car maker</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix and its peers are set for a ‘return to growth,’ analysts say, giving one stock 120% upside</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      text  \\\n",
       "0  Here are Thursday's biggest analyst calls: Apple, Amazon, Tesla, Palantir, DocuSign, Exxon &amp; more     \n",
       "1                                    Buy Las Vegas Sands as travel to Singapore builds, Wells Fargo says     \n",
       "2                   Piper Sandler downgrades DocuSign to sell, citing elevated risks amid CEO transition     \n",
       "3               Analysts react to Tesla's latest earnings, break down what's next for electric car maker     \n",
       "4     Netflix and its peers are set for a ‘return to growth,’ analysts say, giving one stock 120% upside     \n",
       "\n",
       "   label           topic  \n",
       "0      0  Analyst Update  \n",
       "1      0  Analyst Update  \n",
       "2      0  Analyst Update  \n",
       "3      0  Analyst Update  \n",
       "4      0  Analyst Update  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.Series(dataset[\"train\"][\"label\"]).value_counts()\n",
    "data = pd.DataFrame(dataset[\"train\"][::])\n",
    "data[\"topic\"] = data.label.apply(lambda x: topics[x])\n",
    "\n",
    "# clean text: \n",
    "data[\"text\"] = data.text.apply(lambda x: x.replace(\"$AAPL\", \"\"))\n",
    "data[\"text\"] = data.text.apply(lambda x: re.sub(r\"https://\\S+\", \"\", x))\n",
    "data[\"text\"] = data.text.apply(lambda x: re.sub(r\"\\#\\w+\", \"\", x))\n",
    "data[\"text\"] = data.text.apply(lambda x: re.sub(r\"\\@\\w+\", \"\", x))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c2a02aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: Apple, Amazon, Tesla, Palantir, DocuSign, Exxon &amp;amp; more</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Here are Tuesday's biggest analyst calls: Meta, Chipotle, Apple, Tesla, Exxon, Netflix, Sunrun &amp;amp; more</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Apple's near-term future looks murky as consumer spending slows, Bernstein says</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Here are Monday's biggest analyst calls of the day: Tesla, Apple, Yum, Delta, Fox, Netflix &amp;amp; more</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Here are Thursday's biggest analyst calls: Tesla, Amazon, Twitter, Qualcomm, Costco, Apple &amp;amp; more</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyst Update</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                           text  \\\n",
       "0       Here are Thursday's biggest analyst calls: Apple, Amazon, Tesla, Palantir, DocuSign, Exxon &amp; more     \n",
       "13  Here are Tuesday's biggest analyst calls: Meta, Chipotle, Apple, Tesla, Exxon, Netflix, Sunrun &amp; more     \n",
       "20                            Apple's near-term future looks murky as consumer spending slows, Bernstein says     \n",
       "22      Here are Monday's biggest analyst calls of the day: Tesla, Apple, Yum, Delta, Fox, Netflix &amp; more     \n",
       "35      Here are Thursday's biggest analyst calls: Tesla, Amazon, Twitter, Qualcomm, Costco, Apple &amp; more     \n",
       "\n",
       "    label           topic  \n",
       "0       0  Analyst Update  \n",
       "13      0  Analyst Update  \n",
       "20      0  Analyst Update  \n",
       "22      0  Analyst Update  \n",
       "35      0  Analyst Update  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_apple = data[data.text.str.contains(\"apple\", flags=re.IGNORECASE)]\n",
    "raw_apple = raw_apple[~raw_apple.topic.isin([\n",
    "    \"Fed | Central Banks\", \"Dividend\", \"Earnings\", \"Treasuries | Corporate Debt\"\n",
    "])]\n",
    "raw_apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3639a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Company | Product News    66\n",
       "General News | Opinion    23\n",
       "Stock Commentary          15\n",
       "Analyst Update            12\n",
       "Markets                   11\n",
       "Macro                      9\n",
       "Legal | Regulation         8\n",
       "Stock Movement             6\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_apple.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2bc0044b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>text</th>\n",
       "      <th>input</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Analyst Update</td>\n",
       "      <td>- Apple lowering trade-in prices, implies 'strong demand,' BofA says  . More analysts covering Apple are cutting their share-price forecasts, signaling growing concerns about an economic slowdown that could hurt the sales of its products</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Company | Product News</td>\n",
       "      <td>Apple plans to slow hiring and spending growth next year in some divisions to cope with a potential economic downturn  . Apple isn't planning to backfill roles or add new staff on certain teams</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>General News | Opinion</td>\n",
       "      <td>🎧Calorie counts are everywhere. But calories aren’t all that they appear to be.  In the series premiere of Losing it,  dives into how we got the calorie so wrong  ▶️ Apple:   ▶️ Spotify:    .  Good point but the Apple ecosystem is self reinforcing.  I don't think that's the case with Tesla.  Each EV is a stand alone product, and some are better than Tesla.  Mercedes has better range, the EV Mustang is a much better value, etc.  Buyers switch automakers all the time.</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legal | Regulation</td>\n",
       "      <td>: Apple sued by payment card issuers, alleging antitrust competition issues over Apple Pay policies  . : Apple sued by payment card issuers, alleging antitrust competition issues over Apple Pay policies</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macro</td>\n",
       "      <td>The White House expects June’s consumer price index figures to be “highly elevated” as Americans grappled with substantial increases in the cost of gas and food  . The White House expects June’s consumer price index figures to be “highly elevated” as Americans grappled with substantial increases in the cost of gas and food</td>\n",
       "      <td>Apple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    topic  \\\n",
       "0          Analyst Update   \n",
       "1  Company | Product News   \n",
       "2  General News | Opinion   \n",
       "3      Legal | Regulation   \n",
       "4                   Macro   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     text  \\\n",
       "0                                                                                                                                                                                                                                         - Apple lowering trade-in prices, implies 'strong demand,' BofA says  . More analysts covering Apple are cutting their share-price forecasts, signaling growing concerns about an economic slowdown that could hurt the sales of its products     \n",
       "1                                                                                                                                                                                                                                                                                       Apple plans to slow hiring and spending growth next year in some divisions to cope with a potential economic downturn  . Apple isn't planning to backfill roles or add new staff on certain teams   \n",
       "2  🎧Calorie counts are everywhere. But calories aren’t all that they appear to be.  In the series premiere of Losing it,  dives into how we got the calorie so wrong  ▶️ Apple:   ▶️ Spotify:    .  Good point but the Apple ecosystem is self reinforcing.  I don't think that's the case with Tesla.  Each EV is a stand alone product, and some are better than Tesla.  Mercedes has better range, the EV Mustang is a much better value, etc.  Buyers switch automakers all the time.   \n",
       "3                                                                                                                                                                                                                                                                            : Apple sued by payment card issuers, alleging antitrust competition issues over Apple Pay policies  . : Apple sued by payment card issuers, alleging antitrust competition issues over Apple Pay policies     \n",
       "4                                                                                                                                                  The White House expects June’s consumer price index figures to be “highly elevated” as Americans grappled with substantial increases in the cost of gas and food  . The White House expects June’s consumer price index figures to be “highly elevated” as Americans grappled with substantial increases in the cost of gas and food     \n",
       "\n",
       "   input  \n",
       "0  Apple  \n",
       "1  Apple  \n",
       "2  Apple  \n",
       "3  Apple  \n",
       "4  Apple  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apple_train = pd.concat([\n",
    "    raw_apple.groupby(\"topic\")[\"text\"].apply(lambda x: \". \".join(np.random.choice(x, size=2))).reset_index()\n",
    "    for _ in range(100)\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "apple_train[\"input\"] = \"Apple\"\n",
    "apple_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dfe816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c878d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
