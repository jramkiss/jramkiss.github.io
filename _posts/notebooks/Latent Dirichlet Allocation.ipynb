{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4899077e",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1a4c6437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c9a4b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude 'comp.os.ms-windows.misc'\n",
    "categories = [\n",
    "    \"alt.atheism\",\n",
    "    \"comp.graphics\",\n",
    "    \"comp.sys.ibm.pc.hardware\",\n",
    "#     \"comp.sys.mac.hardware\",\n",
    "#     \"comp.windows.x\",\n",
    "#     \"misc.forsale\",\n",
    "#     \"rec.autos\",\n",
    "#     \"rec.motorcycles\",\n",
    "#     \"rec.sport.baseball\",\n",
    "#     \"rec.sport.hockey\",\n",
    "#     \"sci.crypt\",\n",
    "#     \"sci.electronics\",\n",
    "#     \"sci.med\",\n",
    "#     \"sci.space\",\n",
    "#     \"soc.religion.christian\",\n",
    "#     \"talk.politics.guns\",\n",
    "#     \"talk.politics.mideast\",\n",
    "#     \"talk.politics.misc\",\n",
    "#     \"talk.religion.misc\",\n",
    "]\n",
    "\n",
    "newsgroups = fetch_20newsgroups(categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4032bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(newsgroups.data)\n",
    "groups = newsgroups.target\n",
    "group_names = newsgroups.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9be2aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tf features for LDA...\n"
     ]
    }
   ],
   "source": [
    "# Use tf (raw term count) features for LDA.\n",
    "n_words = 100\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=10, max_features=n_words, stop_words=\"english\")\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(data)\n",
    "feature_names = tf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fc5b7c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 0, 0, ..., 1, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 0, 0, ..., 1, 0, 0],\n",
       "       [0, 0, 0, ..., 2, 0, 0]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39910828",
   "metadata": {},
   "source": [
    "## Two-Level Hierarchical Topic Model \n",
    "\n",
    "$$\n",
    "\\theta \\sim Dir(\\alpha) \\\\\n",
    "z_d \\sim Multinom(\\theta) \\\\\n",
    "w_{nd} \\sim p(w \\mid z_d)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b947b9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpyro\n",
    "from numpyro.infer import MCMC, NUTS, Predictive\n",
    "import numpyro.distributions as dist\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8703bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def topic_model2(words):\n",
    "    alpha = numpyro.sample(\"alpha\", ) # global variable alpha, shape = (, n_topics)\n",
    "    beta = numpyro.sample(\"beta\", ) # global beta, shape = (n_topics, n_words)\n",
    "    \n",
    "    with numpyro.plate(\"in_corpus\", n_docs):\n",
    "        # sample topic: \\theta ~ Dir(alpha)\n",
    "        theta = numpyro.sample(\"theta\", dist.Dirichlet(concentration = alpha))\n",
    "        \n",
    "        with numpyro.plate(\"in_document\", n_words):\n",
    "            # sample a topic for each word: z_n ~ Multinom(\\theta)\n",
    "            z = numpyro.sample(\"z\", dist.Multinomial(probs = theta))\n",
    "            # sample a word conditional on the topic: w_n ~ p(w_n | z_n, \\beta)\n",
    "            w = numpyro.sample(\"w\", dist.Categorical(probs=beta))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4437c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(patient_code, Weeks, FVC_obs=None):\n",
    "    μ_α = numpyro.sample(\"μ_α\", dist.Normal(0.0, 500.0))\n",
    "    σ_α = numpyro.sample(\"σ_α\", dist.HalfNormal(100.0))\n",
    "    μ_β = numpyro.sample(\"μ_β\", dist.Normal(0.0, 3.0))\n",
    "    σ_β = numpyro.sample(\"σ_β\", dist.HalfNormal(3.0))\n",
    "\n",
    "    n_patients = len(np.unique(patient_code))\n",
    "\n",
    "    with numpyro.plate(\"plate_i\", n_patients):\n",
    "        α = numpyro.sample(\"α\", dist.Normal(μ_α, σ_α))\n",
    "        β = numpyro.sample(\"β\", dist.Normal(μ_β, σ_β))\n",
    "\n",
    "    σ = numpyro.sample(\"σ\", dist.HalfNormal(100.0))\n",
    "    FVC_est = α[patient_code] + β[patient_code] * Weeks\n",
    "\n",
    "    with numpyro.plate(\"data\", len(patient_code)):\n",
    "        numpyro.sample(\"obs\", dist.Normal(FVC_est, σ), obs=FVC_obs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
